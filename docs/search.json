[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Avocado Forecasts",
    "section": "",
    "text": "This work presents the development of different forecasts for avocado sales volume in the United States to support operational decision making. This analysis aims to find the forecast that best suits each needs based on an evaluation of forecast accuracy in both their point effectiveness and confidence interval accuracy. Two versions of documents are presented, one in English and one in Spanish, which can be accessed from the navigation bar."
  },
  {
    "objectID": "spanish.html",
    "href": "spanish.html",
    "title": "Spanish Version",
    "section": "",
    "text": "A continuación se presenta el desarrollo de distintos pronósticos para el volumen de ventas de Aguacate en Estados Unidos. El documento está dividido por secciones relacionadas con el tipo de proceso o pronóstico.\nModelos a revisar:\n\nSuavización Exponencial\nARIMA\nDescomposición STL\nProphet\nAutorregresión de Redes Neuronales\n\n\n\nPaquetes cargados en la librería necesarios para este análisis.\n\n# Paquetes\npaquetes = c('dplyr','ggplot2','tsibble','fable','feasts',\n             'gridExtra','tseries','fable.prophet','plotly')\nlapply(paquetes, library, character.only=TRUE)\n\n\n\n\nPrimero se realiza una preparación de la base cargada para seleccionar solo los datos de la serie interés, agrupar la información por meses y convertir las unidades del volumen de ventas que está en libras a toneladas. Interesa saber el volumen mensual total de EEUU del tipo de aguacate orgánico.\n\n# El volumen está en libras\n\nserie = datos_aguacate %&gt;% \n  select(Date, TotalVolume, type, region) %&gt;% \n  filter(type == \"organic\" & region == \"TotalUS\") %&gt;% # Total de EEUU\n  mutate(Mes = yearmonth(Date)) %&gt;% \n  group_by(Mes) %&gt;% summarise(Volumen = sum(TotalVolume)) %&gt;% \n  filter(row_number() &lt;= n()-1) %&gt;% #Quitar última fila por información incompleta\n  as_tsibble(index = Mes)\n\n# Convertir volumen de libras a toneladas\nserie$Volumen = (serie$Volumen * 0.453592)/1000\n\n\n\n\n\n\nPrimero se analiza la serie a nivel y se investiga la presencia de estacionalidad.\n\n# Graficar Serie a Nivel\ngraf_san = serie %&gt;% autoplot(Volumen) + geom_point() + \n  labs(y = \"Miles de toneladas\", x = \"\",\n       title = \"Volumen de ventas de aguacate en EEUU, 2015-2023\")\nggplotly(graf_san)\n\n\n\n\n\nSe aprecia que la serie cuenta con una tendencia positiva, así como la posible presencia de heterocedasticidad y estacionalidad.\n\n\n\nAl realizar las siguientes gráficas de estacionalidad con las funciones gg_season() y gg_subseries() se confirma la presencia de esta.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAl sospechar la presencia de heterocedasticidad, se saca una primera diferencia para ver cómo se comporta a lo largo del tiempo.\n\n# Primera Diferencia\nserie_dif = \n  serie %&gt;%\n  mutate(Diferencia = difference(Volumen, order_by = Mes)) %&gt;%\n  select(-Volumen) %&gt;%\n  filter(row_number() &gt; 1)\n\n# Graficar Primera Diferencia\ngraf_serie_dif = serie_dif %&gt;% autoplot(Diferencia) +\n  geom_hline(yintercept = mean(serie_dif$Diferencia),lty=2,col=\"red\") +\n  geom_point() + \n  labs(title = \"Primera Diferencia\", x=\"\")\n\nggplotly(graf_serie_dif)\n\n\n\n\n\nAl ver la gráfica de la primera diferencia se confirma la presencia de heterocedasticidad al ver cómo la varianza va aumentando en el tiempo. Por lo que será necesario realizar alguna transformación.\n\n\n\n\nSe va a realizar una transformación Box-Cox para tratar la heterocedasticidad de la serie para la cual se va a utilizar el método de Guerrero para obtenerla.\n\n# Obtención de Lambda\nlambda = \n  serie %&gt;%\n  features(Volumen, features = guerrero) %&gt;%\n  pull(lambda_guerrero)\n\n# Serie Transformada\ngraf_st = serie %&gt;% \n  autoplot(box_cox(Volumen,lambda)) + \n  geom_point() + \n  labs(\n    title = \"Serie transformada con Box-Cox\",\n    x =\"\", y= \"\"\n  )\n\n# Graficar de comparación de serie a nivel y transformada\ngrid.arrange(graf_san,graf_st)\n\n\n\n\n\n\n\n\nTambién se utiliza una comparación de la primera diferencia de la serie original y la serie transformada para mostrar cómo se corrige la heterocedasticidad mediante la transforamción.\n\n\n\n\n\n\n\n\n\n\n\n\nA continuación se muestra una descomposición de la serie en sus distintos componentes mediante el método STL, acónimo de Seasonal and Trend decomposition using Loess.\n\n\n\n\n\n\n\n\n\nPara identificar mejor los cambios de tendencia en el indicador de tendencia-ciclo, se realiza una gráfica donde cambia de color de acuerdo a la dirección que lleva.\n\n# Tendencia-Ciclo\ntend_ciclo = \n  serie %&gt;%\n  model(STL(box_cox(Volumen,lambda))) %&gt;%\n  components() %&gt;%\n  select(Mes, trend) %&gt;%\n  mutate(dif = difference(trend))\n\n# Color Cambiante para Graficar\nccpg = c()\n#Nota: Está rezagado un periodo para que coincida cuando empieza el cambio\nfor (i in 2:nrow(tend_ciclo)){\n  if(tend_ciclo$dif[i] &gt;= 0){\n    ccpg = append(ccpg, 'black')\n  }else{\n    ccpg = append(ccpg, 'red')\n  }\n}\n#último color igual al último disponible\nccpg = append(ccpg, ccpg[length(ccpg)])\n\n# Gráfica de Tendencia-Ciclo\ntend_ciclo %&gt;%\n  select(-dif) %&gt;%\n  mutate(trend = inv_box_cox(trend,lambda)) %&gt;%\n  ggplot(aes(x = Mes, y = trend)) + \n  geom_line(col=ccpg, lwd=1.5) +\n  labs(title = \"Tendencia-Ciclo de Volumen de Ventas de Aguacate\",\n       subtitle = \"Estados Unidos, 2015 - 2023\",\n       y = \"Miles de toneladas\", x = \"\",\n       )\n\n\n\n\n\n\n\n\n\n\n\nPara evaluar la precisión de los pronósticos se separa la serie en un conjunto de datos de entrenamiento y otro de prueba. Para este ejercicio se busca pronosticar los siguientes 10 periodos (meses).\n\n# Pasos a pronosticar\npap = 10\n\n# Datos de Entrenamiento\nentre_ini = substr(as.character(as.Date(serie$Mes[1])),1,7)\nentre_fin = substr(as.character(as.Date(serie$Mes[nrow(serie)-pap])),1,7)\ndatos_entre = serie %&gt;%\n  filter_index(entre_ini ~ entre_fin)\n\n# Datos de Entrenamiento\nprue_ini = substr(as.character(as.Date(serie$Mes[nrow(serie) - pap + 1])),1,7)\ndatos_prueba = serie %&gt;% filter_index(prue_ini ~.)\n\n\n\n\n\n\nEl primer modelo a revisar es el de Suavización Exponencial para el cual vamos a utilizar las características del comportamiento de la serie previamente identificadas para darnos una idea de cuál sería el mejor modelo para la serie que tenemos.\nCaracterísticas detectadas:\n\nTendencia\nEstacionalidad\nHeterocedasticidad\n\nDado que se detectan estas características se analizarán los siguientes modelos:\n\nETS(M,A,M)\nETS(M,Ad,M)\n\nAdemás, se revisa si el Modelo Automático representa alguna buena alternativa.\n\n# Modelos a Revisar\nmod_se = datos_entre %&gt;%\n  model(\n    Auto = ETS(Volumen), # Modelo automático &lt;ETS(M,Ad,A)&gt;\n    MAM = ETS(Volumen ~ error(\"M\") + trend(\"A\") + season(\"M\")),\n    MAdM = ETS(Volumen ~ error(\"M\") + trend(\"Ad\") + season(\"M\")),\n  )\n\n\n# Criterios de Información (AICc)\nglance(mod_se) %&gt;% arrange(AICc)\n\n# A tibble: 3 × 9\n  .model sigma2 log_lik   AIC  AICc   BIC     MSE    AMSE   MAE\n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Auto   0.0243   -792. 1620. 1628. 1666. 156246. 158324. 0.117\n2 MAM    0.0249   -795. 1625. 1633. 1669. 168550. 176817. 0.121\n3 MAdM   0.0260   -795. 1626. 1635. 1672. 155850. 159705. 0.121\n\n\nSi bien el modelo automático ETS(M,Ad,A) parece mostrar un mejor criterio de información de AICc, este utiliza una estacionalidad aditiva, lo que dada la heterocedasticidad del modelo no es recomendable, por lo que seleccionaremos el modelo ETS(M,Ad,M), el cual tiene más sentido dado el comportamiento de la serie.\nAl evaluar la precisión de los modelos, se observa que el modelo ETS(M,Ad,M) tiene un mejor desempeño que el modelo ETS(M,A,M), por lo cuál se utilizara este, el cual es una Suavización Exponencial con Tendencia Amortiguada, Estacionalidad Multiplicativa y Errores Multiplicativos.\n\n\n# A tibble: 3 × 4\n  .model  RMSE   MAE  MAPE\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Auto    437.  397.  11.8\n2 MAdM    467.  417.  12.3\n3 MAM     592.  452.  13.7\n\n\n\n\n\nUna vez identificado el modelo a utilizar, hay que validarlo mediante el análisis de sus residuales. Primero vamos a revisar los supuestos de \\(E[\\mu]=0\\) y Homocedasticidad.\n\n\n\n\n\n\n\n\n\nSe observa que se cumple con estos supuestos, ahora faltaría ver el supuesto de normalidad.\n\n\n\nSe busca analizar mediante gráficas de histograma, cuantil-cuantil y la prueba Jarque-Bera el supuesto de normalidad de los residuales del modelo.\n\n# Histograma de Residuales\nhist_plot = residuales %&gt;% ggplot(aes(x = .innov)) +\n  geom_histogram(bins = 20, lwd = 1.5,col = 'white', fill = 'slategrey') +\n  labs(title = \"Revisión de Normalidad de Residuales: Histograma y Cuantil-Cuantil\", \n       x = \"Residuales\", y =\"Frecuencia\")\n# Gráfica Cuantil Cuantil\nqq_plot = residuales %&gt;% ggplot(aes(sample = .innov)) + \n  stat_qq(col = 'slateblue') + stat_qq_line() +\n  labs(x = \"Cuantiles Teóricos\", y =\"Cuantiles Muestrales\")\ngrid.arrange(hist_plot,qq_plot)\n\n\n\n\n\n\n\n# Prueba Jarque-Bera\n# p-value &gt; 0.05 indica que no se puede rechazar que se distribuya de manera normal\njarque.bera.test(residuales$.innov)\n\n\n    Jarque Bera Test\n\ndata:  residuales$.innov\nX-squared = 1.4323, df = 2, p-value = 0.4886\n\n\nPudiera ser debatible si se puede considerara válido el supuesto de normalidad dadas las gráficas y la prueba que indica que no se puede rechazar que los residuales se distribuyan de manera normal.\nAnte esta situación se ofrecen dos alternativas para la generación de intervalos de confianza. Se pueden realizar asumiendo distribución normal, o también mediante una simulación Bootstrap.\n\n\n\n\n# Graficar Pronóstico contra Valores reales (Supuesto Distribución Normal)\ngraf_se_dn = mod_se %&gt;% select(MAdM) %&gt;% forecast(h = pap) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Mes &gt;= yearmonth(\"2019-01-01\")),\n    lwd = 1.5,\n    level = 80\n  ) +\n  labs(title = \"Pronóstico con Suavización Exponencial ETS(M,Ad,M)\",\n       subtitle = \"Modelo ETS(M,Ad,M) con Intervalos con Distribución Normal\",\n       x = \"\")\n\n# Graficar Pronóstico contra Valores reales (Bootstrap)\ngraf_se_boot = mod_se %&gt;% select(MAdM) %&gt;% forecast(h = pap, bootstrap = TRUE) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Mes &gt;= yearmonth(\"2019-01-01\")),\n      lwd = 1.5,\n    level = 80\n  ) +\n  labs(subtitle = \"Modelo ETS(M,Ad,M) con Intervalos Bootstrap\",\n       x = \"\")\ngrid.arrange(graf_se_dn,graf_se_boot)\n\n\n\n\n\n\n\n\nNótese que no se observan mayores diferencias entre ambos tipos de intervalos.\n\n\n\n\nEl segundo modelo a revisar es el ARIMA Estacional o SARIMA para el cual también vamos a aprovechar las características del comportamiento de la serie previamente identificadas para darnos una idea de cuáles serían los mejores modelos. Como la serie tiene tendencia y estacionalidad, podría necesitarse sacarse una o más diferencias. Por otro lado, para corregir la heterocedasticidad se puede recurrir a la transformación Box-Cox.\n\n\nPrimero necesitamos que la serie sea estacionaria, para lo cual se sacaron diferencias estacionales y primera diferencia para identificar si es conveniente sacar más de una diferencia y si se prefiere la primera diferencia o la diferencia estacional. Al sacar diferencia estacional, no fue suficiente y se tenía que sacar otra diferencia. Por otro lado, al sacar solo la primera diferencia, parece ser suficiente para volver la serie estacionaria.\n\n# Media de diff(box_cox(Volumen,lambda)) para gráfica de estacionariedad\nm_dif= datos_entre %&gt;% \n  mutate(dif_vol = difference(box_cox(Volumen,lambda))) %&gt;%\n  pull(dif_vol) %&gt;% mean(na.rm = TRUE)\n\n# Gráfica de Diferencias Necesarias para Estacionariedad\ndatos_entre %&gt;% autoplot(\n  box_cox(Volumen,lambda) %&gt;%\n    difference(1)\n)  + geom_point() +\n  labs(\n  title = \"Gráfica de Estacionariedad\",\n  x = \"\", y = \"\"\n) +\n  geom_hline(yintercept = m_dif, lty=2, col=\"red\")\n\n\n\n\n\n\n\n\nTambién se puede apoyar de las pruebas de de Raíz Unitaria y fortaleza estacional para detectar qué diferencias sería más conveniente sacar.\n\n# Prueba de Diferencia Estacional\n# seasonal_strength_year &gt;= 0.64 indica sacar diferencia estacional\ndatos_entre %&gt;% features(box_cox(Volumen,lambda), feat_stl)\n\n# A tibble: 1 × 9\n  trend_strength seasonal_strength_year seasonal_peak_year seasonal_trough_year\n           &lt;dbl&gt;                  &lt;dbl&gt;              &lt;dbl&gt;                &lt;dbl&gt;\n1          0.877                  0.506                  5                   11\n# ℹ 5 more variables: spikiness &lt;dbl&gt;, linearity &lt;dbl&gt;, curvature &lt;dbl&gt;,\n#   stl_e_acf1 &lt;dbl&gt;, stl_e_acf10 &lt;dbl&gt;\n\n# Número de Diferencias Estacionales Necesarias\ndatos_entre %&gt;% features(box_cox(Volumen,lambda), unitroot_nsdiffs)\n\n# A tibble: 1 × 1\n  nsdiffs\n    &lt;int&gt;\n1       0\n\n# Prueba de Raíz Unitaria (versión 1)\n# kpss_pvalue &lt; 0.05 indica sacar diferencia\ndatos_entre %&gt;% features(box_cox(Volumen,lambda), unitroot_kpss)\n\n# A tibble: 1 × 2\n  kpss_stat kpss_pvalue\n      &lt;dbl&gt;       &lt;dbl&gt;\n1      2.08        0.01\n\n# Número de Diferencias Necesarias\ndatos_entre %&gt;% features(box_cox(Volumen,lambda), unitroot_ndiffs)\n\n# A tibble: 1 × 1\n  ndiffs\n   &lt;int&gt;\n1      1\n\n\nLas distintas pruebas indican que lo recomendado sería no sacar diferencia estacional y sacar primera diferencia.\n\n\n\nEl siguiente paso sería revisar las gráficas de Autocorrelación Muestral y Parcial para identificar modelos tentativos.\n\n#Gráficas de Función de Autocorrelación Muestral y Parcial: ACF y PACF\nacf_plot = autoplot(ACF(datos_entre, difference(box_cox(Volumen,lambda)), lag_max = 36)) +\n  labs(y = \"ACF\", x=\"\", title = \"Funciones de Autocorrelación Muestral y Parcial: ACF y PACF\")\npacf_plot = autoplot(PACF(datos_entre, difference(box_cox(Volumen,lambda)), lag_max = 36)) +\n  labs(y = \"PACF\", x= \"Rezagos\")\ngrid.arrange(acf_plot,pacf_plot)\n\n\n\n\n\n\n\n\n\n\n\nSe estimaron distintos modelos con base en los rezagos mostrados en las ACF y PACF y el análisis de residuales.\n\n# Estimar Modelos (d=1,D=0)\nmod_arima = datos_entre %&gt;% \n  model(\n    m210_002 = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(2,1,0) + PDQ(0,0,2)),\n    m011_002 = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(0,1,1) + PDQ(0,0,2)),\n    m810_002_c = ARIMA(box_cox(Volumen,lambda) ~ 1 + pdq(8,1,0) + PDQ(0,0,2)),\n    m217_002_c = ARIMA(box_cox(Volumen,lambda) ~ 1 + pdq(2,1,7) + PDQ(0,0,2)),\n    m312_002 = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(3,1,2) + PDQ(0,0,2)),\n    m119_002 = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(1,1,9) + PDQ(0,0,2))\n  )\n# Modelos ordenados por AICc\nglance(mod_arima) %&gt;% arrange(AICc)\n\n# A tibble: 6 × 8\n  .model     sigma2 log_lik   AIC  AICc   BIC ar_roots  ma_roots  \n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;    &lt;list&gt;    \n1 m810_002_c   20.2   -278.  580.  583.  610. &lt;cpl [8]&gt; &lt;cpl [24]&gt;\n2 m217_002_c   19.4   -277.  580.  584.  613. &lt;cpl [2]&gt; &lt;cpl [31]&gt;\n3 m210_002     21.7   -287.  584.  585.  597. &lt;cpl [2]&gt; &lt;cpl [24]&gt;\n4 m119_002     19.6   -277.  581.  585.  614. &lt;cpl [1]&gt; &lt;cpl [33]&gt;\n5 m011_002     22.8   -290.  587.  588.  597. &lt;cpl [0]&gt; &lt;cpl [25]&gt;\n6 m312_002     22.2   -286.  588.  590.  609. &lt;cpl [3]&gt; &lt;cpl [26]&gt;\n\n# Precisión de Pronósticos\nmod_arima %&gt;% forecast(h = pap) %&gt;% accuracy(datos_prueba) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 6 × 4\n  .model      RMSE   MAE  MAPE\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 m312_002    413.  328.  9.20\n2 m119_002    423.  338.  9.56\n3 m810_002_c  417.  336. 10.2 \n4 m210_002    486.  386. 10.7 \n5 m011_002    516.  412. 11.5 \n6 m217_002_c  674.  587. 17.9 \n\n\nSe separó su análisis por diferenciación para su comparabilidad.\n\n# Estimar Modelos (d=1,D=1)\nmod_arima = datos_entre %&gt;% \n  model(\n    m119_110 = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(1,1,9) + PDQ(1,1,0)),\n    m119_011 = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(1,1,9) + PDQ(0,1,1))\n  )\n# Modelos ordenados por AICc\nglance(mod_arima) %&gt;% arrange(AICc)\n\n# A tibble: 2 × 8\n  .model   sigma2 log_lik   AIC  AICc   BIC ar_roots   ma_roots  \n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;     &lt;list&gt;    \n1 m119_011   22.9   -251.  525.  530.  554. &lt;cpl [1]&gt;  &lt;cpl [21]&gt;\n2 m119_110   23.5   -252.  527.  532.  556. &lt;cpl [13]&gt; &lt;cpl [9]&gt; \n\n# Precisión de Pronósticos\nmod_arima %&gt;% forecast(h = pap) %&gt;% accuracy(datos_prueba) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 2 × 4\n  .model    RMSE   MAE  MAPE\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 m119_110  425.  324.  9.18\n2 m119_011  502.  411. 12.2 \n\n\nY después se eligieron los mejores modelos.\n\n\n# A tibble: 4 × 8\n  .model     sigma2 log_lik   AIC  AICc   BIC ar_roots   ma_roots  \n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;     &lt;list&gt;    \n1 m119_110     23.5   -252.  527.  532.  556. &lt;cpl [13]&gt; &lt;cpl [9]&gt; \n2 m810_002_c   20.2   -278.  580.  583.  610. &lt;cpl [8]&gt;  &lt;cpl [24]&gt;\n3 m119_002     19.6   -277.  581.  585.  614. &lt;cpl [1]&gt;  &lt;cpl [33]&gt;\n4 m312_002     22.2   -286.  588.  590.  609. &lt;cpl [3]&gt;  &lt;cpl [26]&gt;\n\n\n# A tibble: 4 × 4\n  .model      RMSE   MAE  MAPE\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 m119_110    425.  324.  9.18\n2 m312_002    413.  328.  9.20\n3 m119_002    423.  338.  9.56\n4 m810_002_c  417.  336. 10.2 \n\n\nPara la validación de cada modelo se seguía el mismo proceso.\n\n\n\nSe revisaba la significacia estadística de sus componentes y se sacaban sus residuales para analizar que se cumplieran los supuestos.\n\n# Modelo a Revisar\nmar = \"m312_002\"\nresiduales = augment(mod_arima) %&gt;% filter(.model == mar) # Residuales del Modelo a Revisar\n\n# Revisar siginificancia de valores\n#tidy(mod_arima)\nmod_arima %&gt;% select(mar) %&gt;% tidy() %&gt;% print(n=20)\n\n# A tibble: 7 × 6\n  .model   term  estimate std.error statistic   p.value\n  &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 m312_002 ar1    -0.0251     0.256   -0.0980 0.922    \n2 m312_002 ar2     0.276      0.149    1.85   0.0671   \n3 m312_002 ar3     0.357      0.133    2.68   0.00873  \n4 m312_002 ma1    -0.731      0.251   -2.91   0.00450  \n5 m312_002 ma2    -0.169      0.190   -0.888  0.377    \n6 m312_002 sma1    0.511      0.110    4.65   0.0000108\n7 m312_002 sma2    0.518      0.153    3.39   0.00102  \n\n\nSe graficaban los residuales para que se cumplieran los supuestos de \\(E[\\mu]=0\\) y Homocedasticidad.\n\n\n\n\n\n\n\n\n\nSe graficaban las gráficas ACF y PACF de los residuales para revisar la autocorrelación remanente en el modelo.\n\n\n\n\n\n\n\n\n\nAsí como la prueba de Ljung-Box\n\n\n# A mable: 1 x 1\n                   m312_002\n                    &lt;model&gt;\n1 &lt;ARIMA(3,1,2)(0,0,2)[12]&gt;\n\n\n# A tibble: 1 × 3\n  .model   lb_stat lb_pvalue\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 m312_002    43.1  0.000469\n\n\n\n\n\nSe busca analizar mediante gráficas de histograma, cuantil-cuantil y la prueba Jarque-Bera el supuesto de normalidad de los residuales del modelo.\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  residuales$.innov\nX-squared = 1.6021, df = 2, p-value = 0.4489\n\n\n\n\n\nSe graficaron los pronósticos de los principales modelos para compararlos.\n\n# Pronosticar los 4 Mejores Modelos ARIMA\n# Modelos ARIMA para Graficar\nmod_arima_pg = mod_arima %&gt;% \n  select(\n    `ARIMA(1,1,9)(0,0,2)[12]` = m119_002,\n    `ARIMA(3,1,2)(0,0,2)[12]` = m312_002,\n    `ARIMA(8,1,0)(0,0,2)[12] c/ tendencia` = m810_002_c,\n    `ARIMA(1,1,9)(1,1,0)[12]` = m119_110\n  )\n\n# Graficar Pronóstico contra Valores reales\ngraf_arima_4m = mod_arima_pg %&gt;% \n  forecast(h = pap) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Mes &gt;= yearmonth(\"2021-01-01\")),\n    level = NULL\n  ) +\n  labs(title = \"Pronóstico con Modelos ARIMA\",x = \"\") +\n  theme(legend.position='none')  +\n  facet_wrap(vars(.model), ncol = 2)\n\nggplotly(graf_arima_4m)\n\n\n\n\n\nNota: Se puede pasar el cursor sobre la gráfica para ver los valores de cada punto.\nAsí como también se graficaron sus intervalos de confianza.\n\n#Graficar modelos individuales con intervalos de confianza\nmod_arima_pg %&gt;% forecast(h = pap) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Mes &gt;= yearmonth(\"2019-01-01\")),\n    lwd = 1.5,\n  ) +\n  labs(title = \"Pronósticos con Modelos ARIMA\", x = \"\",\n       subtitle = \"Intervalos de confianza de 80% y 95%\") +\n  theme(legend.position='none')  +\n  facet_wrap(vars(.model), scales = \"free\", ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nDespúe se revisó el modelo de Descomposición STL, el cual utiliza dicho método utilizado anteriormente para descomponer la serie, para posteriormente desestacionalizar la serie y aplicarle un componente estacional por medio de algún otro método, como la suacización exponencial (ETS). Como solo se utiliza un método, en este caso se pasa directamente al análisis de residuales\n\n# Estimar Modelo (ETS)\nmod_stl = datos_entre %&gt;% \n  model(\n    dstl = decomposition_model(\n      STL(box_cox(Volumen,lambda)), #Método de descomposición\n      ETS(season_adjust), #Serie desestacionalizada\n      ETS(season_year) #Componente estacional\n      )\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  residuales$.innov\nX-squared = 0.81585, df = 2, p-value = 0.665\n\n\n\n\n\nSe realizan pronósticos con intervalos de confianza con el supuesto de normalidad y Bootstrap.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe realizaron pronósticos también con el modelo de Prophet de Facebook utilizando distintos órdenes y viendo su precisión para elegir el mejor modelo.\n\n# Estimar Modelos\nset.seed(10)\nmod_prophet = datos_entre %&gt;% \n  model(\n    `Order = 10` = prophet(Volumen ~ season(\n      period=\"year\", order = 10, type = \"multiplicative\")),\n    `Order = 5` = prophet(Volumen ~ season(\n      period=\"year\", order = 5, type = \"multiplicative\")),\n    `Order = 3` = prophet(Volumen ~ season(\n      period=\"year\", order = 3, type = \"multiplicative\")),\n    `Order = 2` = prophet(Volumen ~ season(\n      period=\"year\", order = 2, type = \"multiplicative\"))\n    )\n\n# Precisión de Pronósticos\nmod_prophet %&gt;% forecast(h = pap) %&gt;% accuracy(datos_prueba) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 4 × 4\n  .model      RMSE   MAE  MAPE\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Order = 10  748.  579.  17.8\n2 Order = 5   738.  619.  18.9\n3 Order = 2   761.  651.  20.0\n4 Order = 3   788.  652.  20.1\n\n\nUna vez identificado el mejor modelo se procede a su validación.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  residuales$.innov\nX-squared = 1.5829, df = 2, p-value = 0.4532\n\n\n\n\n\nSe graficaron los pronósticos de los principales modelos para compararlos.\n\n\n\n\n\n\nNota: Se puede pasar el cursor sobre la gráfica para ver los valores de cada punto.\nTambién se realizan pronósticos para revisar los intervalos de confianza de cada modelo\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe revisa otro modelo de Autorregresión de Redes Neuronales (NNAR) para ampliar las opciones ofrecidas. Para este modelo se revisan distintos números de nodos y viendo su precisión para elegir el mejor modelo.\n\n# Estimar Modelos NNAR\nset.seed(10) # fijar aleatorios\nmod_rn = datos_entre %&gt;% \n  model(\n    `NNAR(10,1,2)` = NNETAR(box_cox(Volumen,lambda),n_nodes=2),\n    `NNAR(10,1,3)` = NNETAR(box_cox(Volumen,lambda),n_nodes=3),\n    `NNAR(10,1,4)` = NNETAR(box_cox(Volumen,lambda),n_nodes=4),\n    `NNAR(10,1,6)` = NNETAR(box_cox(Volumen,lambda),n_nodes=6)\n  )\n\n# Precisión de Pronósticos\nmod_rn %&gt;% forecast(h = pap) %&gt;% accuracy(datos_prueba) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 4 × 4\n  .model        RMSE   MAE  MAPE\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 NNAR(10,1,3)  363.  345.  10.1\n2 NNAR(10,1,2)  379.  353.  10.5\n3 NNAR(10,1,4)  404.  379.  11.0\n4 NNAR(10,1,6)  467.  416.  11.9\n\n\nUna vez identificado el mejor modelo se procede a su validación.\n\n\n\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWarning: Removed 12 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 12 rows containing non-finite outside the scale range\n(`stat_qq()`).\n\n\nWarning: Removed 12 rows containing non-finite outside the scale range\n(`stat_qq_line()`).\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  na.omit(residuales$.innov)\nX-squared = 3.5995, df = 2, p-value = 0.1653\n\n\n\n\n\nSe realizan pronósticos con intervalos de confianza con el supuesto de normalidad y Bootstrap.\n\n\n\n\n\n\n\n\n\nSe graficaron los pronósticos de los principales modelos para compararlos.\n\n\n\n\n\n\nNota: Se puede pasar el cursor sobre la gráfica para ver los valores de cada punto.\nTambién se realizan pronósticos para revisar los intervalos de confianza de cada modelo\n\n\n\n\n\n\n\n\n\n\n\n\n\nPara realizar una evaluación más completa de de la precisión puntual de los mejores modelos hasta ahora analizados, se procede a hacer una validación cruzada, la cual, es una versión más sofisticada de los conjuntos de entrenamiento y prueba.\nPara este procedimiento es necesaria hacer primero una serie extendida para ir recorriendo una ventana donde se va a ir aumentando el tamaño del conjunto de entrenamiento para ver la precisión en distintos escenarios y obtener un error promedio de estos para evaluar la precisión de cada modelo.\n\n# Crear serie alargada con índice para Validación Cruzada\nserie_alargada = serie %&gt;% \n  stretch_tsibble(.init = 80, .step = 10) %&gt;%\n  filter(.id != max(.id))\n\n# Modelos para validación cruzada\nset.seed(10)\nmod_vc = serie_alargada %&gt;%\n  model(\n    `Suav. Exp. ETS(M,Ad,M)` = ETS(Volumen ~ error(\"M\") + trend(\"Ad\") + season(\"M\")),\n    `ARIMA(1,1,9)(1,1,0)` = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(1,1,9) + PDQ(1,1,0)),\n    `ARIMA(3,1,2)(0,0,2)` = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(3,1,2) + PDQ(0,0,2)),\n    `Decomposición STL` = decomposition_model(STL(box_cox(Volumen,lambda)),\n                                              ETS(season_adjust), ETS(season_year)),\n    `Prophet` = prophet(Volumen ~ season(\n      period=\"year\", order = 10, type = \"multiplicative\")),\n    `Red Neu. AR (10,1,3)` = NNETAR(box_cox(Volumen,lambda),n_nodes=3)\n  )\n\nmod_vc %&gt;% forecast(h = 10) %&gt;% accuracy(serie) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 6 × 4\n  .model                  RMSE   MAE  MAPE\n  &lt;chr&gt;                  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Suav. Exp. ETS(M,Ad,M)  500.  398.  10.6\n2 ARIMA(3,1,2)(0,0,2)     541.  423.  12.4\n3 Prophet                 617.  500.  14.3\n4 Red Neu. AR (10,1,3)    618.  527.  14.8\n5 Decomposición STL       613.  513.  15.0\n6 ARIMA(1,1,9)(1,1,0)     648.  601.  17.3\n\n\n\n\n\nTambién es importante analizar la precisión de los intervalos de confianza de los modelos implementados, para lo cual se muestran distintas formas de evaluar los modelos. Se van a evaluar estos modelos para pronósticos de 10 periodos a pronosticar.\nEmpezamos con el Skill Score, el cual ayudar a ordenar de mejor a peor la precisión general de los intervalos de confianza, donde mientras más alto sea este puntaje van a ser más precisos los posibles intervalos de confianza arrojados por el modelo.\n\n\n# A tibble: 6 × 3\n  .model                 .type skill\n  &lt;chr&gt;                  &lt;chr&gt; &lt;dbl&gt;\n1 Suav. Exp. ETS(M,Ad,M) Test  0.367\n2 ARIMA(3,1,2)(0,0,2)    Test  0.284\n3 Decomposición STL      Test  0.228\n4 Red Neu. AR (10,1,3)   Test  0.173\n5 ARIMA(1,1,9)(1,1,0)    Test  0.166\n6 Prophet                Test  0.160\n\n\nEn la anterior tabla se muestra que el modelo de Suavización Exponencial ETS(M,Ad,M) tiene la mejor precisión general, independientemente del nivel de confianza. Sin embargo, se puede personalizar la evaluación de acuerdo a diferentes necesidades, como intervalos de confianza específicos, o que se priorice la parte inferior o superior del intervalo.\nPor otra parte, el Winkler Score mide la precisión para un determinado nivel de confianza. Mientras más angosto el intervalo, más bajo el Puntaje (Score). Mientras más se salga del intervalo, más se penaliza y el Puntaje aumenta. Por lo tanto, mientras más bajo el Puntaje mejor. Por ejemplo, para pronósticos con un nivel de confianza de 95%, el modelo que mostraría un mejor puntaje sería el Modelo de Descomposicón STL, siendo este el que tenga el mejor balance entre tener un rango más angosto y que a su vez no se salta de este.\n\n\n# A tibble: 6 × 3\n  .model                 .type winkler\n  &lt;chr&gt;                  &lt;chr&gt;   &lt;dbl&gt;\n1 Decomposición STL      Test    2514.\n2 Suav. Exp. ETS(M,Ad,M) Test    2710.\n3 ARIMA(1,1,9)(1,1,0)    Test    2793.\n4 ARIMA(3,1,2)(0,0,2)    Test    2861.\n5 Red Neu. AR (10,1,3)   Test    3517.\n6 Prophet                Test    4477.\n\n\nDe manera similar, el Quantile Score puede servir si alguien está más interesado en que no se sobrepase específcamente el límite inferior o superior del intevalo. Se puede utilizar un puntaje específico para un determinado cuantil. Por ejemplo, si alguien tuviera como prioridad satisfacer una demanda y que no se produzca menos de lo que se pudiera llegar a vender, se puede utilizar un cuantil de 1%:\n\n\n# A tibble: 6 × 3\n  .model                 .type    qs\n  &lt;chr&gt;                  &lt;chr&gt; &lt;dbl&gt;\n1 Decomposición STL      Test   20.4\n2 ARIMA(1,1,9)(1,1,0)    Test   22.1\n3 ARIMA(3,1,2)(0,0,2)    Test   25.5\n4 Suav. Exp. ETS(M,Ad,M) Test   31.0\n5 Red Neu. AR (10,1,3)   Test   46.2\n6 Prophet                Test   90.9\n\n\nPor otro lado, si alguien tuviera como prioridad que no se le quede producto y que no se produzca más de lo que se pudiera vender para evitar la merma, se puede utilizar un cuantil de 90%:\n\n\n# A tibble: 6 × 3\n  .model                 .type    qs\n  &lt;chr&gt;                  &lt;chr&gt; &lt;dbl&gt;\n1 ARIMA(3,1,2)(0,0,2)    Test   207.\n2 Prophet                Test   224.\n3 Red Neu. AR (10,1,3)   Test   235.\n4 Suav. Exp. ETS(M,Ad,M) Test   236.\n5 Decomposición STL      Test   241.\n6 ARIMA(1,1,9)(1,1,0)    Test   265.\n\n\n\n\nFinalmente se presenta una Comparación de los distintos pronósticos para los próximos 10 periodos donde se pueden apreciar sus intervalos de confianza.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDe acuerdo con las necesidades particulares se pueden recomendar distintos Modelos. En términos generales el Modelo de Suavización Exponencial ETS(M,Ad,M) es el que muestra tanto una mejor precisión puntual como un mejor intervalo de confianza medido mediante el Skill Score.\nNo obstante, si de antemano se ha determinado un nivel de confianza, por ejemplo un 95%, el modelo que cuenta con el mejor intervalo de confianza sería el de Modelo de Descomposición STL medido mediante el Winkler Score.\nAsimismo, si lo que más importa es satisfacer una demanda y que no se genere menos de lo que se pudiera llegar a necesitar, por ejemplo para un 99% de confianza, el Modelo de Descomposición STL también sería el mejor según el Quantile Score para un cuantil de 1%.\nPor otra parte, si lo que más preocupa es no generar más de lo que se pudiera llegar a necesitar (como para evitar merma), por ejemplo para un 90% de confianza el modelo indicado sería el Modelo ARIMA(3,1,2)(0,0,2)[12] según el Quantile Score para un cuantil de 90%."
  },
  {
    "objectID": "spanish.html#paquetes",
    "href": "spanish.html#paquetes",
    "title": "Spanish Version",
    "section": "",
    "text": "Paquetes cargados en la librería necesarios para este análisis.\n\n# Paquetes\npaquetes = c('dplyr','ggplot2','tsibble','fable','feasts',\n             'gridExtra','tseries','fable.prophet','plotly')\nlapply(paquetes, library, character.only=TRUE)"
  },
  {
    "objectID": "spanish.html#preparación-de-datos",
    "href": "spanish.html#preparación-de-datos",
    "title": "Spanish Version",
    "section": "",
    "text": "Primero se realiza una preparación de la base cargada para seleccionar solo los datos de la serie interés, agrupar la información por meses y convertir las unidades del volumen de ventas que está en libras a toneladas. Interesa saber el volumen mensual total de EEUU del tipo de aguacate orgánico.\n\n# El volumen está en libras\n\nserie = datos_aguacate %&gt;% \n  select(Date, TotalVolume, type, region) %&gt;% \n  filter(type == \"organic\" & region == \"TotalUS\") %&gt;% # Total de EEUU\n  mutate(Mes = yearmonth(Date)) %&gt;% \n  group_by(Mes) %&gt;% summarise(Volumen = sum(TotalVolume)) %&gt;% \n  filter(row_number() &lt;= n()-1) %&gt;% #Quitar última fila por información incompleta\n  as_tsibble(index = Mes)\n\n# Convertir volumen de libras a toneladas\nserie$Volumen = (serie$Volumen * 0.453592)/1000"
  },
  {
    "objectID": "spanish.html#analizar-serie-a-nivel-estacionalidad-y-heterocedasticidad",
    "href": "spanish.html#analizar-serie-a-nivel-estacionalidad-y-heterocedasticidad",
    "title": "Spanish Version",
    "section": "",
    "text": "Primero se analiza la serie a nivel y se investiga la presencia de estacionalidad.\n\n# Graficar Serie a Nivel\ngraf_san = serie %&gt;% autoplot(Volumen) + geom_point() + \n  labs(y = \"Miles de toneladas\", x = \"\",\n       title = \"Volumen de ventas de aguacate en EEUU, 2015-2023\")\nggplotly(graf_san)\n\n\n\n\n\nSe aprecia que la serie cuenta con una tendencia positiva, así como la posible presencia de heterocedasticidad y estacionalidad.\n\n\n\nAl realizar las siguientes gráficas de estacionalidad con las funciones gg_season() y gg_subseries() se confirma la presencia de esta.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAl sospechar la presencia de heterocedasticidad, se saca una primera diferencia para ver cómo se comporta a lo largo del tiempo.\n\n# Primera Diferencia\nserie_dif = \n  serie %&gt;%\n  mutate(Diferencia = difference(Volumen, order_by = Mes)) %&gt;%\n  select(-Volumen) %&gt;%\n  filter(row_number() &gt; 1)\n\n# Graficar Primera Diferencia\ngraf_serie_dif = serie_dif %&gt;% autoplot(Diferencia) +\n  geom_hline(yintercept = mean(serie_dif$Diferencia),lty=2,col=\"red\") +\n  geom_point() + \n  labs(title = \"Primera Diferencia\", x=\"\")\n\nggplotly(graf_serie_dif)\n\n\n\n\n\nAl ver la gráfica de la primera diferencia se confirma la presencia de heterocedasticidad al ver cómo la varianza va aumentando en el tiempo. Por lo que será necesario realizar alguna transformación."
  },
  {
    "objectID": "spanish.html#transformación-de-la-serie",
    "href": "spanish.html#transformación-de-la-serie",
    "title": "Spanish Version",
    "section": "",
    "text": "Se va a realizar una transformación Box-Cox para tratar la heterocedasticidad de la serie para la cual se va a utilizar el método de Guerrero para obtenerla.\n\n# Obtención de Lambda\nlambda = \n  serie %&gt;%\n  features(Volumen, features = guerrero) %&gt;%\n  pull(lambda_guerrero)\n\n# Serie Transformada\ngraf_st = serie %&gt;% \n  autoplot(box_cox(Volumen,lambda)) + \n  geom_point() + \n  labs(\n    title = \"Serie transformada con Box-Cox\",\n    x =\"\", y= \"\"\n  )\n\n# Graficar de comparación de serie a nivel y transformada\ngrid.arrange(graf_san,graf_st)\n\n\n\n\n\n\n\n\nTambién se utiliza una comparación de la primera diferencia de la serie original y la serie transformada para mostrar cómo se corrige la heterocedasticidad mediante la transforamción."
  },
  {
    "objectID": "spanish.html#descomposición-de-la-serie",
    "href": "spanish.html#descomposición-de-la-serie",
    "title": "Spanish Version",
    "section": "",
    "text": "A continuación se muestra una descomposición de la serie en sus distintos componentes mediante el método STL, acónimo de Seasonal and Trend decomposition using Loess.\n\n\n\n\n\n\n\n\n\nPara identificar mejor los cambios de tendencia en el indicador de tendencia-ciclo, se realiza una gráfica donde cambia de color de acuerdo a la dirección que lleva.\n\n# Tendencia-Ciclo\ntend_ciclo = \n  serie %&gt;%\n  model(STL(box_cox(Volumen,lambda))) %&gt;%\n  components() %&gt;%\n  select(Mes, trend) %&gt;%\n  mutate(dif = difference(trend))\n\n# Color Cambiante para Graficar\nccpg = c()\n#Nota: Está rezagado un periodo para que coincida cuando empieza el cambio\nfor (i in 2:nrow(tend_ciclo)){\n  if(tend_ciclo$dif[i] &gt;= 0){\n    ccpg = append(ccpg, 'black')\n  }else{\n    ccpg = append(ccpg, 'red')\n  }\n}\n#último color igual al último disponible\nccpg = append(ccpg, ccpg[length(ccpg)])\n\n# Gráfica de Tendencia-Ciclo\ntend_ciclo %&gt;%\n  select(-dif) %&gt;%\n  mutate(trend = inv_box_cox(trend,lambda)) %&gt;%\n  ggplot(aes(x = Mes, y = trend)) + \n  geom_line(col=ccpg, lwd=1.5) +\n  labs(title = \"Tendencia-Ciclo de Volumen de Ventas de Aguacate\",\n       subtitle = \"Estados Unidos, 2015 - 2023\",\n       y = \"Miles de toneladas\", x = \"\",\n       )"
  },
  {
    "objectID": "spanish.html#datos-de-entrenamiento-y-prueba",
    "href": "spanish.html#datos-de-entrenamiento-y-prueba",
    "title": "Spanish Version",
    "section": "",
    "text": "Para evaluar la precisión de los pronósticos se separa la serie en un conjunto de datos de entrenamiento y otro de prueba. Para este ejercicio se busca pronosticar los siguientes 10 periodos (meses).\n\n# Pasos a pronosticar\npap = 10\n\n# Datos de Entrenamiento\nentre_ini = substr(as.character(as.Date(serie$Mes[1])),1,7)\nentre_fin = substr(as.character(as.Date(serie$Mes[nrow(serie)-pap])),1,7)\ndatos_entre = serie %&gt;%\n  filter_index(entre_ini ~ entre_fin)\n\n# Datos de Entrenamiento\nprue_ini = substr(as.character(as.Date(serie$Mes[nrow(serie) - pap + 1])),1,7)\ndatos_prueba = serie %&gt;% filter_index(prue_ini ~.)"
  },
  {
    "objectID": "spanish.html#suavización-exponencial",
    "href": "spanish.html#suavización-exponencial",
    "title": "Spanish Version",
    "section": "",
    "text": "El primer modelo a revisar es el de Suavización Exponencial para el cual vamos a utilizar las características del comportamiento de la serie previamente identificadas para darnos una idea de cuál sería el mejor modelo para la serie que tenemos.\nCaracterísticas detectadas:\n\nTendencia\nEstacionalidad\nHeterocedasticidad\n\nDado que se detectan estas características se analizarán los siguientes modelos:\n\nETS(M,A,M)\nETS(M,Ad,M)\n\nAdemás, se revisa si el Modelo Automático representa alguna buena alternativa.\n\n# Modelos a Revisar\nmod_se = datos_entre %&gt;%\n  model(\n    Auto = ETS(Volumen), # Modelo automático &lt;ETS(M,Ad,A)&gt;\n    MAM = ETS(Volumen ~ error(\"M\") + trend(\"A\") + season(\"M\")),\n    MAdM = ETS(Volumen ~ error(\"M\") + trend(\"Ad\") + season(\"M\")),\n  )\n\n\n# Criterios de Información (AICc)\nglance(mod_se) %&gt;% arrange(AICc)\n\n# A tibble: 3 × 9\n  .model sigma2 log_lik   AIC  AICc   BIC     MSE    AMSE   MAE\n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Auto   0.0243   -792. 1620. 1628. 1666. 156246. 158324. 0.117\n2 MAM    0.0249   -795. 1625. 1633. 1669. 168550. 176817. 0.121\n3 MAdM   0.0260   -795. 1626. 1635. 1672. 155850. 159705. 0.121\n\n\nSi bien el modelo automático ETS(M,Ad,A) parece mostrar un mejor criterio de información de AICc, este utiliza una estacionalidad aditiva, lo que dada la heterocedasticidad del modelo no es recomendable, por lo que seleccionaremos el modelo ETS(M,Ad,M), el cual tiene más sentido dado el comportamiento de la serie.\nAl evaluar la precisión de los modelos, se observa que el modelo ETS(M,Ad,M) tiene un mejor desempeño que el modelo ETS(M,A,M), por lo cuál se utilizara este, el cual es una Suavización Exponencial con Tendencia Amortiguada, Estacionalidad Multiplicativa y Errores Multiplicativos.\n\n\n# A tibble: 3 × 4\n  .model  RMSE   MAE  MAPE\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Auto    437.  397.  11.8\n2 MAdM    467.  417.  12.3\n3 MAM     592.  452.  13.7\n\n\n\n\n\nUna vez identificado el modelo a utilizar, hay que validarlo mediante el análisis de sus residuales. Primero vamos a revisar los supuestos de \\(E[\\mu]=0\\) y Homocedasticidad.\n\n\n\n\n\n\n\n\n\nSe observa que se cumple con estos supuestos, ahora faltaría ver el supuesto de normalidad.\n\n\n\nSe busca analizar mediante gráficas de histograma, cuantil-cuantil y la prueba Jarque-Bera el supuesto de normalidad de los residuales del modelo.\n\n# Histograma de Residuales\nhist_plot = residuales %&gt;% ggplot(aes(x = .innov)) +\n  geom_histogram(bins = 20, lwd = 1.5,col = 'white', fill = 'slategrey') +\n  labs(title = \"Revisión de Normalidad de Residuales: Histograma y Cuantil-Cuantil\", \n       x = \"Residuales\", y =\"Frecuencia\")\n# Gráfica Cuantil Cuantil\nqq_plot = residuales %&gt;% ggplot(aes(sample = .innov)) + \n  stat_qq(col = 'slateblue') + stat_qq_line() +\n  labs(x = \"Cuantiles Teóricos\", y =\"Cuantiles Muestrales\")\ngrid.arrange(hist_plot,qq_plot)\n\n\n\n\n\n\n\n# Prueba Jarque-Bera\n# p-value &gt; 0.05 indica que no se puede rechazar que se distribuya de manera normal\njarque.bera.test(residuales$.innov)\n\n\n    Jarque Bera Test\n\ndata:  residuales$.innov\nX-squared = 1.4323, df = 2, p-value = 0.4886\n\n\nPudiera ser debatible si se puede considerara válido el supuesto de normalidad dadas las gráficas y la prueba que indica que no se puede rechazar que los residuales se distribuyan de manera normal.\nAnte esta situación se ofrecen dos alternativas para la generación de intervalos de confianza. Se pueden realizar asumiendo distribución normal, o también mediante una simulación Bootstrap.\n\n\n\n\n# Graficar Pronóstico contra Valores reales (Supuesto Distribución Normal)\ngraf_se_dn = mod_se %&gt;% select(MAdM) %&gt;% forecast(h = pap) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Mes &gt;= yearmonth(\"2019-01-01\")),\n    lwd = 1.5,\n    level = 80\n  ) +\n  labs(title = \"Pronóstico con Suavización Exponencial ETS(M,Ad,M)\",\n       subtitle = \"Modelo ETS(M,Ad,M) con Intervalos con Distribución Normal\",\n       x = \"\")\n\n# Graficar Pronóstico contra Valores reales (Bootstrap)\ngraf_se_boot = mod_se %&gt;% select(MAdM) %&gt;% forecast(h = pap, bootstrap = TRUE) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Mes &gt;= yearmonth(\"2019-01-01\")),\n      lwd = 1.5,\n    level = 80\n  ) +\n  labs(subtitle = \"Modelo ETS(M,Ad,M) con Intervalos Bootstrap\",\n       x = \"\")\ngrid.arrange(graf_se_dn,graf_se_boot)\n\n\n\n\n\n\n\n\nNótese que no se observan mayores diferencias entre ambos tipos de intervalos."
  },
  {
    "objectID": "spanish.html#arima",
    "href": "spanish.html#arima",
    "title": "Spanish Version",
    "section": "",
    "text": "El segundo modelo a revisar es el ARIMA Estacional o SARIMA para el cual también vamos a aprovechar las características del comportamiento de la serie previamente identificadas para darnos una idea de cuáles serían los mejores modelos. Como la serie tiene tendencia y estacionalidad, podría necesitarse sacarse una o más diferencias. Por otro lado, para corregir la heterocedasticidad se puede recurrir a la transformación Box-Cox.\n\n\nPrimero necesitamos que la serie sea estacionaria, para lo cual se sacaron diferencias estacionales y primera diferencia para identificar si es conveniente sacar más de una diferencia y si se prefiere la primera diferencia o la diferencia estacional. Al sacar diferencia estacional, no fue suficiente y se tenía que sacar otra diferencia. Por otro lado, al sacar solo la primera diferencia, parece ser suficiente para volver la serie estacionaria.\n\n# Media de diff(box_cox(Volumen,lambda)) para gráfica de estacionariedad\nm_dif= datos_entre %&gt;% \n  mutate(dif_vol = difference(box_cox(Volumen,lambda))) %&gt;%\n  pull(dif_vol) %&gt;% mean(na.rm = TRUE)\n\n# Gráfica de Diferencias Necesarias para Estacionariedad\ndatos_entre %&gt;% autoplot(\n  box_cox(Volumen,lambda) %&gt;%\n    difference(1)\n)  + geom_point() +\n  labs(\n  title = \"Gráfica de Estacionariedad\",\n  x = \"\", y = \"\"\n) +\n  geom_hline(yintercept = m_dif, lty=2, col=\"red\")\n\n\n\n\n\n\n\n\nTambién se puede apoyar de las pruebas de de Raíz Unitaria y fortaleza estacional para detectar qué diferencias sería más conveniente sacar.\n\n# Prueba de Diferencia Estacional\n# seasonal_strength_year &gt;= 0.64 indica sacar diferencia estacional\ndatos_entre %&gt;% features(box_cox(Volumen,lambda), feat_stl)\n\n# A tibble: 1 × 9\n  trend_strength seasonal_strength_year seasonal_peak_year seasonal_trough_year\n           &lt;dbl&gt;                  &lt;dbl&gt;              &lt;dbl&gt;                &lt;dbl&gt;\n1          0.877                  0.506                  5                   11\n# ℹ 5 more variables: spikiness &lt;dbl&gt;, linearity &lt;dbl&gt;, curvature &lt;dbl&gt;,\n#   stl_e_acf1 &lt;dbl&gt;, stl_e_acf10 &lt;dbl&gt;\n\n# Número de Diferencias Estacionales Necesarias\ndatos_entre %&gt;% features(box_cox(Volumen,lambda), unitroot_nsdiffs)\n\n# A tibble: 1 × 1\n  nsdiffs\n    &lt;int&gt;\n1       0\n\n# Prueba de Raíz Unitaria (versión 1)\n# kpss_pvalue &lt; 0.05 indica sacar diferencia\ndatos_entre %&gt;% features(box_cox(Volumen,lambda), unitroot_kpss)\n\n# A tibble: 1 × 2\n  kpss_stat kpss_pvalue\n      &lt;dbl&gt;       &lt;dbl&gt;\n1      2.08        0.01\n\n# Número de Diferencias Necesarias\ndatos_entre %&gt;% features(box_cox(Volumen,lambda), unitroot_ndiffs)\n\n# A tibble: 1 × 1\n  ndiffs\n   &lt;int&gt;\n1      1\n\n\nLas distintas pruebas indican que lo recomendado sería no sacar diferencia estacional y sacar primera diferencia.\n\n\n\nEl siguiente paso sería revisar las gráficas de Autocorrelación Muestral y Parcial para identificar modelos tentativos.\n\n#Gráficas de Función de Autocorrelación Muestral y Parcial: ACF y PACF\nacf_plot = autoplot(ACF(datos_entre, difference(box_cox(Volumen,lambda)), lag_max = 36)) +\n  labs(y = \"ACF\", x=\"\", title = \"Funciones de Autocorrelación Muestral y Parcial: ACF y PACF\")\npacf_plot = autoplot(PACF(datos_entre, difference(box_cox(Volumen,lambda)), lag_max = 36)) +\n  labs(y = \"PACF\", x= \"Rezagos\")\ngrid.arrange(acf_plot,pacf_plot)\n\n\n\n\n\n\n\n\n\n\n\nSe estimaron distintos modelos con base en los rezagos mostrados en las ACF y PACF y el análisis de residuales.\n\n# Estimar Modelos (d=1,D=0)\nmod_arima = datos_entre %&gt;% \n  model(\n    m210_002 = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(2,1,0) + PDQ(0,0,2)),\n    m011_002 = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(0,1,1) + PDQ(0,0,2)),\n    m810_002_c = ARIMA(box_cox(Volumen,lambda) ~ 1 + pdq(8,1,0) + PDQ(0,0,2)),\n    m217_002_c = ARIMA(box_cox(Volumen,lambda) ~ 1 + pdq(2,1,7) + PDQ(0,0,2)),\n    m312_002 = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(3,1,2) + PDQ(0,0,2)),\n    m119_002 = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(1,1,9) + PDQ(0,0,2))\n  )\n# Modelos ordenados por AICc\nglance(mod_arima) %&gt;% arrange(AICc)\n\n# A tibble: 6 × 8\n  .model     sigma2 log_lik   AIC  AICc   BIC ar_roots  ma_roots  \n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;    &lt;list&gt;    \n1 m810_002_c   20.2   -278.  580.  583.  610. &lt;cpl [8]&gt; &lt;cpl [24]&gt;\n2 m217_002_c   19.4   -277.  580.  584.  613. &lt;cpl [2]&gt; &lt;cpl [31]&gt;\n3 m210_002     21.7   -287.  584.  585.  597. &lt;cpl [2]&gt; &lt;cpl [24]&gt;\n4 m119_002     19.6   -277.  581.  585.  614. &lt;cpl [1]&gt; &lt;cpl [33]&gt;\n5 m011_002     22.8   -290.  587.  588.  597. &lt;cpl [0]&gt; &lt;cpl [25]&gt;\n6 m312_002     22.2   -286.  588.  590.  609. &lt;cpl [3]&gt; &lt;cpl [26]&gt;\n\n# Precisión de Pronósticos\nmod_arima %&gt;% forecast(h = pap) %&gt;% accuracy(datos_prueba) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 6 × 4\n  .model      RMSE   MAE  MAPE\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 m312_002    413.  328.  9.20\n2 m119_002    423.  338.  9.56\n3 m810_002_c  417.  336. 10.2 \n4 m210_002    486.  386. 10.7 \n5 m011_002    516.  412. 11.5 \n6 m217_002_c  674.  587. 17.9 \n\n\nSe separó su análisis por diferenciación para su comparabilidad.\n\n# Estimar Modelos (d=1,D=1)\nmod_arima = datos_entre %&gt;% \n  model(\n    m119_110 = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(1,1,9) + PDQ(1,1,0)),\n    m119_011 = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(1,1,9) + PDQ(0,1,1))\n  )\n# Modelos ordenados por AICc\nglance(mod_arima) %&gt;% arrange(AICc)\n\n# A tibble: 2 × 8\n  .model   sigma2 log_lik   AIC  AICc   BIC ar_roots   ma_roots  \n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;     &lt;list&gt;    \n1 m119_011   22.9   -251.  525.  530.  554. &lt;cpl [1]&gt;  &lt;cpl [21]&gt;\n2 m119_110   23.5   -252.  527.  532.  556. &lt;cpl [13]&gt; &lt;cpl [9]&gt; \n\n# Precisión de Pronósticos\nmod_arima %&gt;% forecast(h = pap) %&gt;% accuracy(datos_prueba) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 2 × 4\n  .model    RMSE   MAE  MAPE\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 m119_110  425.  324.  9.18\n2 m119_011  502.  411. 12.2 \n\n\nY después se eligieron los mejores modelos.\n\n\n# A tibble: 4 × 8\n  .model     sigma2 log_lik   AIC  AICc   BIC ar_roots   ma_roots  \n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;     &lt;list&gt;    \n1 m119_110     23.5   -252.  527.  532.  556. &lt;cpl [13]&gt; &lt;cpl [9]&gt; \n2 m810_002_c   20.2   -278.  580.  583.  610. &lt;cpl [8]&gt;  &lt;cpl [24]&gt;\n3 m119_002     19.6   -277.  581.  585.  614. &lt;cpl [1]&gt;  &lt;cpl [33]&gt;\n4 m312_002     22.2   -286.  588.  590.  609. &lt;cpl [3]&gt;  &lt;cpl [26]&gt;\n\n\n# A tibble: 4 × 4\n  .model      RMSE   MAE  MAPE\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 m119_110    425.  324.  9.18\n2 m312_002    413.  328.  9.20\n3 m119_002    423.  338.  9.56\n4 m810_002_c  417.  336. 10.2 \n\n\nPara la validación de cada modelo se seguía el mismo proceso.\n\n\n\nSe revisaba la significacia estadística de sus componentes y se sacaban sus residuales para analizar que se cumplieran los supuestos.\n\n# Modelo a Revisar\nmar = \"m312_002\"\nresiduales = augment(mod_arima) %&gt;% filter(.model == mar) # Residuales del Modelo a Revisar\n\n# Revisar siginificancia de valores\n#tidy(mod_arima)\nmod_arima %&gt;% select(mar) %&gt;% tidy() %&gt;% print(n=20)\n\n# A tibble: 7 × 6\n  .model   term  estimate std.error statistic   p.value\n  &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 m312_002 ar1    -0.0251     0.256   -0.0980 0.922    \n2 m312_002 ar2     0.276      0.149    1.85   0.0671   \n3 m312_002 ar3     0.357      0.133    2.68   0.00873  \n4 m312_002 ma1    -0.731      0.251   -2.91   0.00450  \n5 m312_002 ma2    -0.169      0.190   -0.888  0.377    \n6 m312_002 sma1    0.511      0.110    4.65   0.0000108\n7 m312_002 sma2    0.518      0.153    3.39   0.00102  \n\n\nSe graficaban los residuales para que se cumplieran los supuestos de \\(E[\\mu]=0\\) y Homocedasticidad.\n\n\n\n\n\n\n\n\n\nSe graficaban las gráficas ACF y PACF de los residuales para revisar la autocorrelación remanente en el modelo.\n\n\n\n\n\n\n\n\n\nAsí como la prueba de Ljung-Box\n\n\n# A mable: 1 x 1\n                   m312_002\n                    &lt;model&gt;\n1 &lt;ARIMA(3,1,2)(0,0,2)[12]&gt;\n\n\n# A tibble: 1 × 3\n  .model   lb_stat lb_pvalue\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 m312_002    43.1  0.000469\n\n\n\n\n\nSe busca analizar mediante gráficas de histograma, cuantil-cuantil y la prueba Jarque-Bera el supuesto de normalidad de los residuales del modelo.\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  residuales$.innov\nX-squared = 1.6021, df = 2, p-value = 0.4489\n\n\n\n\n\nSe graficaron los pronósticos de los principales modelos para compararlos.\n\n# Pronosticar los 4 Mejores Modelos ARIMA\n# Modelos ARIMA para Graficar\nmod_arima_pg = mod_arima %&gt;% \n  select(\n    `ARIMA(1,1,9)(0,0,2)[12]` = m119_002,\n    `ARIMA(3,1,2)(0,0,2)[12]` = m312_002,\n    `ARIMA(8,1,0)(0,0,2)[12] c/ tendencia` = m810_002_c,\n    `ARIMA(1,1,9)(1,1,0)[12]` = m119_110\n  )\n\n# Graficar Pronóstico contra Valores reales\ngraf_arima_4m = mod_arima_pg %&gt;% \n  forecast(h = pap) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Mes &gt;= yearmonth(\"2021-01-01\")),\n    level = NULL\n  ) +\n  labs(title = \"Pronóstico con Modelos ARIMA\",x = \"\") +\n  theme(legend.position='none')  +\n  facet_wrap(vars(.model), ncol = 2)\n\nggplotly(graf_arima_4m)\n\n\n\n\n\nNota: Se puede pasar el cursor sobre la gráfica para ver los valores de cada punto.\nAsí como también se graficaron sus intervalos de confianza.\n\n#Graficar modelos individuales con intervalos de confianza\nmod_arima_pg %&gt;% forecast(h = pap) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Mes &gt;= yearmonth(\"2019-01-01\")),\n    lwd = 1.5,\n  ) +\n  labs(title = \"Pronósticos con Modelos ARIMA\", x = \"\",\n       subtitle = \"Intervalos de confianza de 80% y 95%\") +\n  theme(legend.position='none')  +\n  facet_wrap(vars(.model), scales = \"free\", ncol = 2)"
  },
  {
    "objectID": "spanish.html#pronóstico-con-descomposición-stl",
    "href": "spanish.html#pronóstico-con-descomposición-stl",
    "title": "Spanish Version",
    "section": "",
    "text": "Despúe se revisó el modelo de Descomposición STL, el cual utiliza dicho método utilizado anteriormente para descomponer la serie, para posteriormente desestacionalizar la serie y aplicarle un componente estacional por medio de algún otro método, como la suacización exponencial (ETS). Como solo se utiliza un método, en este caso se pasa directamente al análisis de residuales\n\n# Estimar Modelo (ETS)\nmod_stl = datos_entre %&gt;% \n  model(\n    dstl = decomposition_model(\n      STL(box_cox(Volumen,lambda)), #Método de descomposición\n      ETS(season_adjust), #Serie desestacionalizada\n      ETS(season_year) #Componente estacional\n      )\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  residuales$.innov\nX-squared = 0.81585, df = 2, p-value = 0.665\n\n\n\n\n\nSe realizan pronósticos con intervalos de confianza con el supuesto de normalidad y Bootstrap."
  },
  {
    "objectID": "spanish.html#pronóstico-con-prophet",
    "href": "spanish.html#pronóstico-con-prophet",
    "title": "Spanish Version",
    "section": "",
    "text": "Se realizaron pronósticos también con el modelo de Prophet de Facebook utilizando distintos órdenes y viendo su precisión para elegir el mejor modelo.\n\n# Estimar Modelos\nset.seed(10)\nmod_prophet = datos_entre %&gt;% \n  model(\n    `Order = 10` = prophet(Volumen ~ season(\n      period=\"year\", order = 10, type = \"multiplicative\")),\n    `Order = 5` = prophet(Volumen ~ season(\n      period=\"year\", order = 5, type = \"multiplicative\")),\n    `Order = 3` = prophet(Volumen ~ season(\n      period=\"year\", order = 3, type = \"multiplicative\")),\n    `Order = 2` = prophet(Volumen ~ season(\n      period=\"year\", order = 2, type = \"multiplicative\"))\n    )\n\n# Precisión de Pronósticos\nmod_prophet %&gt;% forecast(h = pap) %&gt;% accuracy(datos_prueba) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 4 × 4\n  .model      RMSE   MAE  MAPE\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Order = 10  748.  579.  17.8\n2 Order = 5   738.  619.  18.9\n3 Order = 2   761.  651.  20.0\n4 Order = 3   788.  652.  20.1\n\n\nUna vez identificado el mejor modelo se procede a su validación.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  residuales$.innov\nX-squared = 1.5829, df = 2, p-value = 0.4532\n\n\n\n\n\nSe graficaron los pronósticos de los principales modelos para compararlos.\n\n\n\n\n\n\nNota: Se puede pasar el cursor sobre la gráfica para ver los valores de cada punto.\nTambién se realizan pronósticos para revisar los intervalos de confianza de cada modelo"
  },
  {
    "objectID": "spanish.html#pronóstico-con-autorregresión-de-redes-neuronales-nnar",
    "href": "spanish.html#pronóstico-con-autorregresión-de-redes-neuronales-nnar",
    "title": "Spanish Version",
    "section": "",
    "text": "Se revisa otro modelo de Autorregresión de Redes Neuronales (NNAR) para ampliar las opciones ofrecidas. Para este modelo se revisan distintos números de nodos y viendo su precisión para elegir el mejor modelo.\n\n# Estimar Modelos NNAR\nset.seed(10) # fijar aleatorios\nmod_rn = datos_entre %&gt;% \n  model(\n    `NNAR(10,1,2)` = NNETAR(box_cox(Volumen,lambda),n_nodes=2),\n    `NNAR(10,1,3)` = NNETAR(box_cox(Volumen,lambda),n_nodes=3),\n    `NNAR(10,1,4)` = NNETAR(box_cox(Volumen,lambda),n_nodes=4),\n    `NNAR(10,1,6)` = NNETAR(box_cox(Volumen,lambda),n_nodes=6)\n  )\n\n# Precisión de Pronósticos\nmod_rn %&gt;% forecast(h = pap) %&gt;% accuracy(datos_prueba) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 4 × 4\n  .model        RMSE   MAE  MAPE\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 NNAR(10,1,3)  363.  345.  10.1\n2 NNAR(10,1,2)  379.  353.  10.5\n3 NNAR(10,1,4)  404.  379.  11.0\n4 NNAR(10,1,6)  467.  416.  11.9\n\n\nUna vez identificado el mejor modelo se procede a su validación.\n\n\n\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 12 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nWarning: Removed 12 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 12 rows containing non-finite outside the scale range\n(`stat_qq()`).\n\n\nWarning: Removed 12 rows containing non-finite outside the scale range\n(`stat_qq_line()`).\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  na.omit(residuales$.innov)\nX-squared = 3.5995, df = 2, p-value = 0.1653\n\n\n\n\n\nSe realizan pronósticos con intervalos de confianza con el supuesto de normalidad y Bootstrap.\n\n\n\n\n\n\n\n\n\nSe graficaron los pronósticos de los principales modelos para compararlos.\n\n\n\n\n\n\nNota: Se puede pasar el cursor sobre la gráfica para ver los valores de cada punto.\nTambién se realizan pronósticos para revisar los intervalos de confianza de cada modelo"
  },
  {
    "objectID": "spanish.html#validación-cruzada",
    "href": "spanish.html#validación-cruzada",
    "title": "Spanish Version",
    "section": "",
    "text": "Para realizar una evaluación más completa de de la precisión puntual de los mejores modelos hasta ahora analizados, se procede a hacer una validación cruzada, la cual, es una versión más sofisticada de los conjuntos de entrenamiento y prueba.\nPara este procedimiento es necesaria hacer primero una serie extendida para ir recorriendo una ventana donde se va a ir aumentando el tamaño del conjunto de entrenamiento para ver la precisión en distintos escenarios y obtener un error promedio de estos para evaluar la precisión de cada modelo.\n\n# Crear serie alargada con índice para Validación Cruzada\nserie_alargada = serie %&gt;% \n  stretch_tsibble(.init = 80, .step = 10) %&gt;%\n  filter(.id != max(.id))\n\n# Modelos para validación cruzada\nset.seed(10)\nmod_vc = serie_alargada %&gt;%\n  model(\n    `Suav. Exp. ETS(M,Ad,M)` = ETS(Volumen ~ error(\"M\") + trend(\"Ad\") + season(\"M\")),\n    `ARIMA(1,1,9)(1,1,0)` = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(1,1,9) + PDQ(1,1,0)),\n    `ARIMA(3,1,2)(0,0,2)` = ARIMA(box_cox(Volumen,lambda) ~ 0 + pdq(3,1,2) + PDQ(0,0,2)),\n    `Decomposición STL` = decomposition_model(STL(box_cox(Volumen,lambda)),\n                                              ETS(season_adjust), ETS(season_year)),\n    `Prophet` = prophet(Volumen ~ season(\n      period=\"year\", order = 10, type = \"multiplicative\")),\n    `Red Neu. AR (10,1,3)` = NNETAR(box_cox(Volumen,lambda),n_nodes=3)\n  )\n\nmod_vc %&gt;% forecast(h = 10) %&gt;% accuracy(serie) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 6 × 4\n  .model                  RMSE   MAE  MAPE\n  &lt;chr&gt;                  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Suav. Exp. ETS(M,Ad,M)  500.  398.  10.6\n2 ARIMA(3,1,2)(0,0,2)     541.  423.  12.4\n3 Prophet                 617.  500.  14.3\n4 Red Neu. AR (10,1,3)    618.  527.  14.8\n5 Decomposición STL       613.  513.  15.0\n6 ARIMA(1,1,9)(1,1,0)     648.  601.  17.3"
  },
  {
    "objectID": "spanish.html#precisión-de-la-distribución",
    "href": "spanish.html#precisión-de-la-distribución",
    "title": "Spanish Version",
    "section": "",
    "text": "También es importante analizar la precisión de los intervalos de confianza de los modelos implementados, para lo cual se muestran distintas formas de evaluar los modelos. Se van a evaluar estos modelos para pronósticos de 10 periodos a pronosticar.\nEmpezamos con el Skill Score, el cual ayudar a ordenar de mejor a peor la precisión general de los intervalos de confianza, donde mientras más alto sea este puntaje van a ser más precisos los posibles intervalos de confianza arrojados por el modelo.\n\n\n# A tibble: 6 × 3\n  .model                 .type skill\n  &lt;chr&gt;                  &lt;chr&gt; &lt;dbl&gt;\n1 Suav. Exp. ETS(M,Ad,M) Test  0.367\n2 ARIMA(3,1,2)(0,0,2)    Test  0.284\n3 Decomposición STL      Test  0.228\n4 Red Neu. AR (10,1,3)   Test  0.173\n5 ARIMA(1,1,9)(1,1,0)    Test  0.166\n6 Prophet                Test  0.160\n\n\nEn la anterior tabla se muestra que el modelo de Suavización Exponencial ETS(M,Ad,M) tiene la mejor precisión general, independientemente del nivel de confianza. Sin embargo, se puede personalizar la evaluación de acuerdo a diferentes necesidades, como intervalos de confianza específicos, o que se priorice la parte inferior o superior del intervalo.\nPor otra parte, el Winkler Score mide la precisión para un determinado nivel de confianza. Mientras más angosto el intervalo, más bajo el Puntaje (Score). Mientras más se salga del intervalo, más se penaliza y el Puntaje aumenta. Por lo tanto, mientras más bajo el Puntaje mejor. Por ejemplo, para pronósticos con un nivel de confianza de 95%, el modelo que mostraría un mejor puntaje sería el Modelo de Descomposicón STL, siendo este el que tenga el mejor balance entre tener un rango más angosto y que a su vez no se salta de este.\n\n\n# A tibble: 6 × 3\n  .model                 .type winkler\n  &lt;chr&gt;                  &lt;chr&gt;   &lt;dbl&gt;\n1 Decomposición STL      Test    2514.\n2 Suav. Exp. ETS(M,Ad,M) Test    2710.\n3 ARIMA(1,1,9)(1,1,0)    Test    2793.\n4 ARIMA(3,1,2)(0,0,2)    Test    2861.\n5 Red Neu. AR (10,1,3)   Test    3517.\n6 Prophet                Test    4477.\n\n\nDe manera similar, el Quantile Score puede servir si alguien está más interesado en que no se sobrepase específcamente el límite inferior o superior del intevalo. Se puede utilizar un puntaje específico para un determinado cuantil. Por ejemplo, si alguien tuviera como prioridad satisfacer una demanda y que no se produzca menos de lo que se pudiera llegar a vender, se puede utilizar un cuantil de 1%:\n\n\n# A tibble: 6 × 3\n  .model                 .type    qs\n  &lt;chr&gt;                  &lt;chr&gt; &lt;dbl&gt;\n1 Decomposición STL      Test   20.4\n2 ARIMA(1,1,9)(1,1,0)    Test   22.1\n3 ARIMA(3,1,2)(0,0,2)    Test   25.5\n4 Suav. Exp. ETS(M,Ad,M) Test   31.0\n5 Red Neu. AR (10,1,3)   Test   46.2\n6 Prophet                Test   90.9\n\n\nPor otro lado, si alguien tuviera como prioridad que no se le quede producto y que no se produzca más de lo que se pudiera vender para evitar la merma, se puede utilizar un cuantil de 90%:\n\n\n# A tibble: 6 × 3\n  .model                 .type    qs\n  &lt;chr&gt;                  &lt;chr&gt; &lt;dbl&gt;\n1 ARIMA(3,1,2)(0,0,2)    Test   207.\n2 Prophet                Test   224.\n3 Red Neu. AR (10,1,3)   Test   235.\n4 Suav. Exp. ETS(M,Ad,M) Test   236.\n5 Decomposición STL      Test   241.\n6 ARIMA(1,1,9)(1,1,0)    Test   265.\n\n\n\n\nFinalmente se presenta una Comparación de los distintos pronósticos para los próximos 10 periodos donde se pueden apreciar sus intervalos de confianza."
  },
  {
    "objectID": "spanish.html#conclusiones",
    "href": "spanish.html#conclusiones",
    "title": "Spanish Version",
    "section": "",
    "text": "De acuerdo con las necesidades particulares se pueden recomendar distintos Modelos. En términos generales el Modelo de Suavización Exponencial ETS(M,Ad,M) es el que muestra tanto una mejor precisión puntual como un mejor intervalo de confianza medido mediante el Skill Score.\nNo obstante, si de antemano se ha determinado un nivel de confianza, por ejemplo un 95%, el modelo que cuenta con el mejor intervalo de confianza sería el de Modelo de Descomposición STL medido mediante el Winkler Score.\nAsimismo, si lo que más importa es satisfacer una demanda y que no se genere menos de lo que se pudiera llegar a necesitar, por ejemplo para un 99% de confianza, el Modelo de Descomposición STL también sería el mejor según el Quantile Score para un cuantil de 1%.\nPor otra parte, si lo que más preocupa es no generar más de lo que se pudiera llegar a necesitar (como para evitar merma), por ejemplo para un 90% de confianza el modelo indicado sería el Modelo ARIMA(3,1,2)(0,0,2)[12] según el Quantile Score para un cuantil de 90%."
  },
  {
    "objectID": "english.html",
    "href": "english.html",
    "title": "English Version",
    "section": "",
    "text": "The following document presents the development of different forecasts for avocado sales volume in the United States. The document is divided by sections related to the type of process or forecast.\nModels:\n\nExponential Smoothing\nARIMA\nSTL Decomposition\nProphet\nNeural Network Auto-Regression\n\n\n\nPackages loaded in the library required for this analysis.\n\n# Packages\npackages = c('dplyr','ggplot2','tsibble','fable','feasts',\n             'gridExtra','tseries','fable.prophet','plotly')\nlapply(packages, library, character.only=TRUE)\n\n\n\n\nFirst, the loaded database is prepared in order to select only the data of the series of interest, group the information by months and convert the units of the sales volume in pounds to tons. We are interested in knowing the total US monthly volume of organic avocados.\n\nserie = avocado_data %&gt;% \n  select(Date, TotalVolume, type, region) %&gt;% \n  filter(type == \"organic\" & region == \"TotalUS\") %&gt;%\n  mutate(Month = yearmonth(Date)) %&gt;% \n  group_by(Month) %&gt;% summarise(Volume = sum(TotalVolume)) %&gt;% \n  filter(row_number() &lt;= n()-1) %&gt;% #Remove last row due to incomplete information\n  as_tsibble(index = Month)\n\n# Convert volume from pounds to tons\nserie$Volume = (serie$Volume * 0.453592)/1000\n\n\n\n\n\n\nFirst, the original series is analyzed and the presence of seasonality is investigated.\n\n# Plot Original Series\ngraf_san = serie %&gt;% autoplot(Volume) + geom_point() + \n  labs(y = \"Thousands of tons\", x = \"\",\n       title = \"Avocado sales volume in the U.S., 2015-2023\")\nggplotly(graf_san)\n\n\n\n\n\nIt can be seen that the series has a positive trend, as well as the possible presence of heteroscedasticity and seasonality.\n\n\n\nThe following seasonality plots with the gg_season() and gg_subseries() functions confirm the presence of seasonality.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen suspecting the presence of heteroscedasticity, a first difference is drawn to see how it behaves over time.\n\n# First Difference\nserie_dif = \n  serie %&gt;%\n  mutate(Difference = difference(Volume, order_by = Month)) %&gt;%\n  select(-Volume) %&gt;%\n  filter(row_number() &gt; 1)\n\n# Graficar First Difference\ngraf_serie_dif = serie_dif %&gt;% autoplot(Difference) +\n  geom_hline(yintercept = mean(serie_dif$Difference),lty=2,col=\"red\") +\n  geom_point() + \n  labs(title = \"First Difference\", x=\"\")\n\nggplotly(graf_serie_dif)\n\n\n\n\n\nLooking at the plot of the first difference confirms the presence of heteroscedasticity as the variance increases over time. Therefore, it will be necessary to perform some transformation.\n\n\n\n\nA Box-Cox transformation will be performed to deal with the heteroscedasticity of the series for which the Guerrero method will be used to obtain it.\n\n# Estimating Lambda\nlambda = \n  serie %&gt;%\n  features(Volume, features = guerrero) %&gt;%\n  pull(lambda_guerrero)\n\n# Transformed Series\ngraf_st = serie %&gt;% \n  autoplot(box_cox(Volume,lambda)) + \n  geom_point() + \n  labs(\n    title = \"Box-Cox transformed series\",\n    x =\"\", y= \"\"\n  )\n\n# Original and transformed series comparison graphs\ngrid.arrange(graf_san,graf_st)\n\n\n\n\n\n\n\n\nA comparison of the first difference of the original series and the transformed series is also used to show how heteroscedasticity is corrected by the transformation.\n\n\n\n\n\n\n\n\n\n\n\n\nThe following is a decomposition of the series into its various components using the STL method, which stands for Seasonal and Trend decomposition using Loess.\n\n\n\n\n\n\n\n\n\nTo better identify trend changes in the trend-cycle indicator, a graph is made where it changes color according to its direction.\n\n# Trend-Cycle\ntrend_cycle = \n  serie %&gt;%\n  model(STL(box_cox(Volume,lambda))) %&gt;%\n  components() %&gt;%\n  select(Month, trend) %&gt;%\n  mutate(dif = difference(trend))\n\n# Shifting Color for Plotting\nccpg = c()\n#Note: One period is lagged to coincide with the start of the changeover.\nfor (i in 2:nrow(trend_cycle)){\n  if(trend_cycle$dif[i] &gt;= 0){\n    ccpg = append(ccpg, 'black')\n  }else{\n    ccpg = append(ccpg, 'red')\n  }\n}\n#last color equal to the last color available\nccpg = append(ccpg, ccpg[length(ccpg)])\n\n# Trend-Cycle Graph\ntrend_cycle %&gt;%\n  select(-dif) %&gt;%\n  mutate(trend = inv_box_cox(trend,lambda)) %&gt;%\n  ggplot(aes(x = Month, y = trend)) + \n  geom_line(col=ccpg, lwd=1.5) +\n  labs(title = \"Avocado Sales Volume Trend-Cycle\",\n       subtitle = \"United States, 2015 - 2023\",\n       y = \"Thousands of tons\", x = \"\",\n       )\n\n\n\n\n\n\n\n\n\n\n\nTo evaluate the accuracy of the forecasts, the series is separated into a training data set and a test data set. For this exercise we seek to forecast the following 10 periods (Months).\n\n# Steps to forecast\npap = 10\n\n# Training Data\ntrain_ini = substr(as.character(as.Date(serie$Month[1])),1,7)\ntrain_end = substr(as.character(as.Date(serie$Month[nrow(serie)-pap])),1,7)\ntrain_data = serie %&gt;%\n  filter_index(train_ini ~ train_end)\n\n# Test Data\ntest_ini = substr(as.character(as.Date(serie$Month[nrow(serie) - pap + 1])),1,7)\ntest_data = serie %&gt;% filter_index(test_ini ~.)\n\n\n\n\n\n\nThe first model to review is the Exponential Smoothing model for which we are going to use the characteristics of the behavior of the series previously identified to give us an idea of what would be the best model for the series we have.\nIdentified characteristics:\n\nTrend\nSeasonality\nHeterocedasticity\n\nSince these characteristics are detected, the following models will be analyzed:\n\nETS(M,A,M)\nETS(M,Ad,M)\n\nIn addition, it is reviewed whether the Automatic Model represents a good alternative.\n\n# Models to Review\nmod_se = train_data %&gt;%\n  model(\n    Auto = ETS(Volume), # Automatic model &lt;ETS(M,Ad,A)&gt;\n    MAM = ETS(Volume ~ error(\"M\") + trend(\"A\") + season(\"M\")),\n    MAdM = ETS(Volume ~ error(\"M\") + trend(\"Ad\") + season(\"M\")),\n  )\n\n\n# Information Criteria (AICc)\nglance(mod_se) %&gt;% arrange(AICc)\n\n# A tibble: 3 × 9\n  .model sigma2 log_lik   AIC  AICc   BIC     MSE    AMSE   MAE\n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Auto   0.0243   -792. 1620. 1628. 1666. 156246. 158324. 0.117\n2 MAM    0.0249   -795. 1625. 1633. 1669. 168550. 176817. 0.121\n3 MAdM   0.0260   -795. 1626. 1635. 1672. 155850. 159705. 0.121\n\n\nAlthough the ETS(M,Ad,A) automatic model seems to show a better information criterion of AICc, it uses an additive stationarity, which given the heteroscedasticity of the model is not recommended, so we will select the ETS(M,Ad,M) model, which makes more sense given the behavior of the series.\nWhen evaluating the accuracy of the models, it is observed that the ETS(M,Ad,M) model has a better performance than the ETS(M,A,M) model, so we will use the latter, which is an Exponential Smoothing with Damped Trend, Multiplicative Stationarity and Multiplicative Errors.\n\n\n# A tibble: 3 × 4\n  .model  RMSE   MAE  MAPE\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Auto    437.  397.  11.8\n2 MAdM    467.  417.  12.3\n3 MAM     592.  452.  13.7\n\n\n\n\n\nOnce the model to be used has been identified, it must be validated by analyzing its residuals. First we will review the assumptions of \\(E[mu]=0\\) and homoscedasticity.\n\n\n\n\n\n\n\n\n\nIt can be seen that these assumptions are fulfilled, now it remains to see the assumption of normality.\n\n\n\nWe seek to analyze by means of histogram, quantile-quantile plots and the Jarque-Bera test the assumption of normality of the residuals of the model.\n\n# Residuals histogram\nhist_plot = residuals %&gt;% ggplot(aes(x = .innov)) +\n  geom_histogram(bins = 20, lwd = 1.5,col = 'white', fill = 'slategrey') +\n  labs(title = \"Residuals Normality Check: Histogram and Quantile-Quantile\", \n       x = \"Residuals\", y =\"Frequency\")\n# Q-Q Plot\nqq_plot = residuals %&gt;% ggplot(aes(sample = .innov)) + \n  stat_qq(col = 'slateblue') + stat_qq_line() +\n  labs(x = \"Theoretical Quantiles\", y =\"Sample Quantiles\")\ngrid.arrange(hist_plot,qq_plot)\n\n\n\n\n\n\n\n# Jarque-Bera Test\n# p-value &gt; 0.05 indicates that it cannot be rejected as normally distributed.\njarque.bera.test(residuals$.innov)\n\n\n    Jarque Bera Test\n\ndata:  residuals$.innov\nX-squared = 1.4323, df = 2, p-value = 0.4886\n\n\nIt may be debatable whether the assumption of normality can be considered valid given the plots and the test that indicates that it cannot be rejected that the residuals are normally distributed.\nIn this situation, two alternatives are offered for the generation of confidence intervals. They can be performed assuming normal distribution, or also by means of a Bootstrap simulation.\n\n\n\n\n# Plot Forecast vs. Actual Values (Normal Distribution Assumption)\ngraf_se_dn = mod_se %&gt;% select(MAdM) %&gt;% forecast(h = pap) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Month &gt;= yearmonth(\"2019-01-01\")),\n    lwd = 1.5,\n    level = 80\n  ) +\n  labs(title = \"Exponential Smoothing Forecast ETS(M,Ad,M)\",\n       subtitle = \"ETS(M,Ad,M) Model with Normally Distributed Intervals\",\n       x = \"\")\n\n# Plot Forecast vs. Actual Values (Bootstrap)\ngraf_se_boot = mod_se %&gt;% select(MAdM) %&gt;% forecast(h = pap, bootstrap = TRUE) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Month &gt;= yearmonth(\"2019-01-01\")),\n      lwd = 1.5,\n    level = 80\n  ) +\n  labs(subtitle = \"ETS(M,Ad,M) Model with Bootstrap Intervals\",\n       x = \"\")\ngrid.arrange(graf_se_dn,graf_se_boot)\n\n\n\n\n\n\n\n\nNote that no major differences are observed between the two types of intervals.\n\n\n\n\nThe second model to review is the Seasonal ARIMA or SARIMA for which we will also take advantage of the previously identified characteristics of the behavior of the series to give us an idea of which would be the best models. As the series has trend and seasonality, one or more differences may need to be drawn. On the other hand, the Box-Cox transformation can be used to correct for heteroscedasticity.\n\n\nFirst we need the series to be stationary, for which we calculated seasonal differences and first difference to identify if it is convenient to estimate more than one difference and if the first difference or the seasonal difference is preferred. When applying seasonal difference, it was not enough and another difference had to be computed On the other hand, by estimating only the first difference, it seems to be enough to make the series stationary.\n\n# diff(box_cox(Volume,lambda)) Mean for stationarity graph\nm_dif= train_data %&gt;% \n  mutate(dif_vol = difference(box_cox(Volume,lambda))) %&gt;%\n  pull(dif_vol) %&gt;% mean(na.rm = TRUE)\n\n# Plot of Differences Required for Stationarity\ntrain_data %&gt;% autoplot(\n  box_cox(Volume,lambda) %&gt;%\n    difference(1)\n)  + geom_point() +\n  labs(\n  title = \"Stationarity Graph\",\n  x = \"\", y = \"\"\n) +\n  geom_hline(yintercept = m_dif, lty=2, col=\"red\")\n\n\n\n\n\n\n\n\nThe Unit Root and Seasonal Strength tests can also be used to detect which differences would be more convenient to calculate.\n\n# Seasonal Difference Test\n# seasonal_strength_year &gt;= 0.64 indicates to calculate seasonal difference\ntrain_data %&gt;% features(box_cox(Volume,lambda), feat_stl)\n\n# A tibble: 1 × 9\n  trend_strength seasonal_strength_year seasonal_peak_year seasonal_trough_year\n           &lt;dbl&gt;                  &lt;dbl&gt;              &lt;dbl&gt;                &lt;dbl&gt;\n1          0.877                  0.506                  5                   11\n# ℹ 5 more variables: spikiness &lt;dbl&gt;, linearity &lt;dbl&gt;, curvature &lt;dbl&gt;,\n#   stl_e_acf1 &lt;dbl&gt;, stl_e_acf10 &lt;dbl&gt;\n\n# Number of Seasonal Differences Required\ntrain_data %&gt;% features(box_cox(Volume,lambda), unitroot_nsdiffs)\n\n# A tibble: 1 × 1\n  nsdiffs\n    &lt;int&gt;\n1       0\n\n# Unit Root Test\n# kpss_pvalue &lt; 0.05 indicates calculate difference\ntrain_data %&gt;% features(box_cox(Volume,lambda), unitroot_kpss)\n\n# A tibble: 1 × 2\n  kpss_stat kpss_pvalue\n      &lt;dbl&gt;       &lt;dbl&gt;\n1      2.08        0.01\n\n# Number of Differences Required\ntrain_data %&gt;% features(box_cox(Volume,lambda), unitroot_ndiffs)\n\n# A tibble: 1 × 1\n  ndiffs\n   &lt;int&gt;\n1      1\n\n\nThe various tests indicate that the recommended approach would be not to calculate seasonal difference and to calculate first difference.\n\n\n\nThe next step would be to review the Sample and Partial Autocorrelation plots to identify tentative models.\n\n# Sample and Partial Autocorrelation Function Plots: ACF y PACF\nacf_plot = autoplot(ACF(train_data, difference(box_cox(Volume,lambda)), lag_max = 36)) +\n  labs(y = \"ACF\", x=\"\", title = \"Sample and Partial Autocorrelation Functions: ACF and PACF\")\npacf_plot = autoplot(PACF(train_data, difference(box_cox(Volume,lambda)), lag_max = 36)) +\n  labs(y = \"PACF\", x= \"Lags\")\ngrid.arrange(acf_plot,pacf_plot)\n\n\n\n\n\n\n\n\n\n\n\nDifferent models were estimated based on the lags shown in the ACF and PACF and the analysis of residuals.\n\n# Estimate Model (d=1,D=0)\nmod_arima = train_data %&gt;% \n  model(\n    m210_002 = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(2,1,0) + PDQ(0,0,2)),\n    m011_002 = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(0,1,1) + PDQ(0,0,2)),\n    m810_002_c = ARIMA(box_cox(Volume,lambda) ~ 1 + pdq(8,1,0) + PDQ(0,0,2)),\n    m217_002_c = ARIMA(box_cox(Volume,lambda) ~ 1 + pdq(2,1,7) + PDQ(0,0,2)),\n    m312_002 = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(3,1,2) + PDQ(0,0,2)),\n    m119_002 = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(1,1,9) + PDQ(0,0,2))\n  )\n# Models sorted by AICc\nglance(mod_arima) %&gt;% arrange(AICc)\n\n# A tibble: 6 × 8\n  .model     sigma2 log_lik   AIC  AICc   BIC ar_roots  ma_roots  \n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;    &lt;list&gt;    \n1 m810_002_c   20.2   -278.  580.  583.  610. &lt;cpl [8]&gt; &lt;cpl [24]&gt;\n2 m217_002_c   19.4   -277.  580.  584.  613. &lt;cpl [2]&gt; &lt;cpl [31]&gt;\n3 m210_002     21.7   -287.  584.  585.  597. &lt;cpl [2]&gt; &lt;cpl [24]&gt;\n4 m119_002     19.6   -277.  581.  585.  614. &lt;cpl [1]&gt; &lt;cpl [33]&gt;\n5 m011_002     22.8   -290.  587.  588.  597. &lt;cpl [0]&gt; &lt;cpl [25]&gt;\n6 m312_002     22.2   -286.  588.  590.  609. &lt;cpl [3]&gt; &lt;cpl [26]&gt;\n\n# Forecast Accuracy\nmod_arima %&gt;% forecast(h = pap) %&gt;% accuracy(test_data) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 6 × 4\n  .model      RMSE   MAE  MAPE\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 m312_002    413.  328.  9.20\n2 m119_002    423.  338.  9.56\n3 m810_002_c  417.  336. 10.2 \n4 m210_002    486.  386. 10.7 \n5 m011_002    516.  412. 11.5 \n6 m217_002_c  674.  587. 17.9 \n\n\nTheir analysis was separated by differentiation for comparability.\n\n# Estimate Model (d=1,D=1)\nmod_arima = train_data %&gt;% \n  model(\n    m119_110 = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(1,1,9) + PDQ(1,1,0)),\n    m119_011 = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(1,1,9) + PDQ(0,1,1))\n  )\n# Models sorted by AICc\nglance(mod_arima) %&gt;% arrange(AICc)\n\n# A tibble: 2 × 8\n  .model   sigma2 log_lik   AIC  AICc   BIC ar_roots   ma_roots  \n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;     &lt;list&gt;    \n1 m119_011   22.9   -251.  525.  530.  554. &lt;cpl [1]&gt;  &lt;cpl [21]&gt;\n2 m119_110   23.5   -252.  527.  532.  556. &lt;cpl [13]&gt; &lt;cpl [9]&gt; \n\n# Forecast Accuracy\nmod_arima %&gt;% forecast(h = pap) %&gt;% accuracy(test_data) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 2 × 4\n  .model    RMSE   MAE  MAPE\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 m119_110  425.  324.  9.18\n2 m119_011  502.  411. 12.2 \n\n\nY después se eligieron los mejores modelos.\n\n\n# A tibble: 4 × 8\n  .model     sigma2 log_lik   AIC  AICc   BIC ar_roots   ma_roots  \n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;     &lt;list&gt;    \n1 m119_110     23.5   -252.  527.  532.  556. &lt;cpl [13]&gt; &lt;cpl [9]&gt; \n2 m810_002_c   20.2   -278.  580.  583.  610. &lt;cpl [8]&gt;  &lt;cpl [24]&gt;\n3 m119_002     19.6   -277.  581.  585.  614. &lt;cpl [1]&gt;  &lt;cpl [33]&gt;\n4 m312_002     22.2   -286.  588.  590.  609. &lt;cpl [3]&gt;  &lt;cpl [26]&gt;\n\n\n# A tibble: 4 × 4\n  .model      RMSE   MAE  MAPE\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 m119_110    425.  324.  9.18\n2 m312_002    413.  328.  9.20\n3 m119_002    423.  338.  9.56\n4 m810_002_c  417.  336. 10.2 \n\n\nThe same process was followed for the validation of each model.\n\n\n\nThe statistical significance of its components was reviewed and their residuals were extracted to analyze whether the assumptions were met.\n\n# Model to Review\nmar = \"m312_002\"\nresiduals = augment(mod_arima) %&gt;% filter(.model == mar) # Residuals of the Model to Review\n\n# Review significance of values\n#tidy(mod_arima)\nmod_arima %&gt;% select(mar) %&gt;% tidy() %&gt;% print(n=20)\n\n# A tibble: 7 × 6\n  .model   term  estimate std.error statistic   p.value\n  &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 m312_002 ar1    -0.0251     0.256   -0.0980 0.922    \n2 m312_002 ar2     0.276      0.149    1.85   0.0671   \n3 m312_002 ar3     0.357      0.133    2.68   0.00873  \n4 m312_002 ma1    -0.731      0.251   -2.91   0.00450  \n5 m312_002 ma2    -0.169      0.190   -0.888  0.377    \n6 m312_002 sma1    0.511      0.110    4.65   0.0000108\n7 m312_002 sma2    0.518      0.153    3.39   0.00102  \n\n\nThe residuals were plotted so that the assumptions of \\(E[mu]=0\\) and homoscedasticity were met.\n\n\n\n\n\n\n\n\n\nACF and PACF plots of the residuals were plotted to check for remaining autocorrelation in the model.\n\n\n\n\n\n\n\n\n\nAs well as the Ljung-Box test.\n\n\n# A mable: 1 x 1\n                   m312_002\n                    &lt;model&gt;\n1 &lt;ARIMA(3,1,2)(0,0,2)[12]&gt;\n\n\n# A tibble: 1 × 3\n  .model   lb_stat lb_pvalue\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 m312_002    43.1  0.000469\n\n\n\n\n\nWe seek to analyze by means of histogram, Q-Q plots and the Jarque-Bera test the assumption of normality of the residuals of the model.\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  residuals$.innov\nX-squared = 1.6021, df = 2, p-value = 0.4489\n\n\n\n\n\nThe forecasts of the main models were plotted for comparison.\n\n# Forecasting the Top 4 ARIMA Models\n# ARIMA Models for Plotting\nmod_arima_pg = mod_arima %&gt;% \n  select(\n    `ARIMA(1,1,9)(0,0,2)[12]` = m119_002,\n    `ARIMA(3,1,2)(0,0,2)[12]` = m312_002,\n    `ARIMA(8,1,0)(0,0,2)[12] c/ tendencia` = m810_002_c,\n    `ARIMA(1,1,9)(1,1,0)[12]` = m119_110\n  )\n\n# Plot Forecast vs. Actual values\ngraf_arima_4m = mod_arima_pg %&gt;% \n  forecast(h = pap) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Month &gt;= yearmonth(\"2021-01-01\")),\n    level = NULL\n  ) +\n  labs(title = \"Forecasting with ARIMA Models\",x = \"\") +\n  theme(legend.position='none')  +\n  facet_wrap(vars(.model), ncol = 2)\n\nggplotly(graf_arima_4m)\n\n\n\n\n\nNote: You can hover the cursor over the graph to see the values of each point.\nTheir confidence intervals were also plotted.\n\n# Plotting individual models with confidence intervals\nmod_arima_pg %&gt;% forecast(h = pap) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Month &gt;= yearmonth(\"2019-01-01\")),\n    lwd = 1.5,\n  ) +\n  labs(title = \"Forecasting with ARIMA Models\", x = \"\",\n       subtitle = \"80% and 95% confidence intervals\") +\n  theme(legend.position='none')  +\n  facet_wrap(vars(.model), scales = \"free\", ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nAfterwards, the STL Decomposition model was reviewed, which uses the previously used method to decompose the series, to subsequently deseasonalize the series and apply a seasonal component by means of some other method, such as exponential smoothing (ETS). Since only one method is used, in this case we go directly to the residual analysis.\n\n# Estimate Model (ETS)\nmod_stl = train_data %&gt;% \n  model(\n    dstl = decomposition_model(\n      STL(box_cox(Volume,lambda)), #Decomposition method\n      ETS(season_adjust), #Seasonally adjusted series\n      ETS(season_year) #Seasonal component\n      )\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  residuals$.innov\nX-squared = 0.81585, df = 2, p-value = 0.665\n\n\n\n\n\nForecasts are made with confidence intervals with the assumption of normality and Bootstrap.\n\n\n\n\n\n\n\n\n\n\n\n\n\nForecasts were also made with the Facebook Prophet model using different orders and looking at their accuracy to choose the best model.\n\n# Estimating Models\nset.seed(10)\nmod_prophet = train_data %&gt;% \n  model(\n    `Order = 10` = prophet(Volume ~ season(\n      period=\"year\", order = 10, type = \"multiplicative\")),\n    `Order = 5` = prophet(Volume ~ season(\n      period=\"year\", order = 5, type = \"multiplicative\")),\n    `Order = 3` = prophet(Volume ~ season(\n      period=\"year\", order = 3, type = \"multiplicative\")),\n    `Order = 2` = prophet(Volume ~ season(\n      period=\"year\", order = 2, type = \"multiplicative\"))\n    )\n\n# Forecast Accuracy\nmod_prophet %&gt;% forecast(h = pap) %&gt;% accuracy(test_data) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 4 × 4\n  .model      RMSE   MAE  MAPE\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Order = 10  748.  579.  17.8\n2 Order = 5   738.  619.  18.9\n3 Order = 2   761.  651.  20.0\n4 Order = 3   788.  652.  20.1\n\n\nOnce the best model has been identified, it is validated.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  residuals$.innov\nX-squared = 1.5829, df = 2, p-value = 0.4532\n\n\n\n\n\nThe forecasts of the main models were plotted for comparison.\n\n\n\n\n\n\nNote: You can hover the cursor over the graph to see the values of each point.\nForecasts are also performed to check the confidence intervals of each model.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Neural Network AutoRegressive Regression (NNAR) model is also reviewed to expand the options offered. For this model, different numbers of nodes are reviewed and their accuracy is reviewed to choose the best model.\n\n# Estimating Models NNAR\nset.seed(10) # set random numbers\nmod_rn = train_data %&gt;% \n  model(\n    `NNAR(10,1,2)` = NNETAR(box_cox(Volume,lambda),n_nodes=2),\n    `NNAR(10,1,3)` = NNETAR(box_cox(Volume,lambda),n_nodes=3),\n    `NNAR(10,1,4)` = NNETAR(box_cox(Volume,lambda),n_nodes=4),\n    `NNAR(10,1,6)` = NNETAR(box_cox(Volume,lambda),n_nodes=6)\n  )\n\n# Forecast Accuracy\nmod_rn %&gt;% forecast(h = pap) %&gt;% accuracy(test_data) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 4 × 4\n  .model        RMSE   MAE  MAPE\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 NNAR(10,1,3)  363.  345.  10.1\n2 NNAR(10,1,2)  379.  353.  10.5\n3 NNAR(10,1,4)  404.  379.  11.0\n4 NNAR(10,1,6)  467.  416.  11.9\n\n\nOnce the best model has been identified, it is validated.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  na.omit(residuals$.innov)\nX-squared = 3.5995, df = 2, p-value = 0.1653\n\n\n\n\n\nForecasts are made with confidence intervals with the assumption of normality and Bootstrap.\n\n\n\n\n\n\n\n\n\nThe forecasts of the main models were plotted for comparison.\n\n\n\n\n\n\nNote: You can hover the cursor over the graph to see the values of each point.\nForecasts are also performed to check the confidence intervals of each model.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn order to perform a more complete evaluation of the point accuracy of the best models so far analyzed, a cross-validation is performed, which is a more sophisticated version of the training and test sets.\nFor this procedure it is necessary to first make an extended series to go through a window where the size of the training set will be increased to see the accuracy in different scenarios and obtain an average error of these to evaluate the accuracy of each model.\n\n# Create extended series with index for Cross-Validation\nserie_alargada = serie %&gt;% \n  stretch_tsibble(.init = 80, .step = 10) %&gt;%\n  filter(.id != max(.id))\n\n# Models for cross-validation\nset.seed(10)\nmod_vc = serie_alargada %&gt;%\n  model(\n    `Exp. Smo. ETS(M,Ad,M)` = ETS(Volume ~ error(\"M\") + trend(\"Ad\") + season(\"M\")),\n    `ARIMA(1,1,9)(1,1,0)` = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(1,1,9) + PDQ(1,1,0)),\n    `ARIMA(3,1,2)(0,0,2)` = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(3,1,2) + PDQ(0,0,2)),\n    `STL decomposition` = decomposition_model(STL(box_cox(Volume,lambda)),\n                                              ETS(season_adjust), ETS(season_year)),\n    `Prophet` = prophet(Volume ~ season(\n      period=\"year\", order = 10, type = \"multiplicative\")),\n    `Neu. Net AR (10,1,3)` = NNETAR(box_cox(Volume,lambda),n_nodes=3)\n  )\n\nmod_vc %&gt;% forecast(h = 10) %&gt;% accuracy(serie) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 6 × 4\n  .model                 RMSE   MAE  MAPE\n  &lt;chr&gt;                 &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Exp. Smo. ETS(M,Ad,M)  500.  398.  10.6\n2 ARIMA(3,1,2)(0,0,2)    541.  423.  12.4\n3 Prophet                617.  500.  14.3\n4 Neu. Net AR (10,1,3)   618.  527.  14.8\n5 STL decomposition      613.  513.  15.0\n6 ARIMA(1,1,9)(1,1,0)    648.  601.  17.3\n\n\n\n\n\nIt is also important to analyze the accuracy of the confidence intervals of the implemented models, for which different ways of evaluating the models are shown. These models will be evaluated for 10-period forecasts.\nWe start with the Skill Score, which helps to rank the overall accuracy of the confidence intervals from best to worst, where the higher this score is, the more accurate the possible confidence intervals returned by the model will be.\n\n\n# A tibble: 6 × 3\n  .model                .type skill\n  &lt;chr&gt;                 &lt;chr&gt; &lt;dbl&gt;\n1 Exp. Smo. ETS(M,Ad,M) Test  0.367\n2 ARIMA(3,1,2)(0,0,2)   Test  0.284\n3 STL decomposition     Test  0.228\n4 Neu. Net AR (10,1,3)  Test  0.173\n5 ARIMA(1,1,9)(1,1,0)   Test  0.166\n6 Prophet               Test  0.160\n\n\nThe above table shows that the Exponential Smoothing model ETS(M,Ad,M) has the best overall accuracy, regardless of the confidence level. However, the evaluation can be customized according to different needs, such as specific confidence intervals, or prioritizing the lower or upper part of the interval.\nOn the other hand, the Winkler Score measures the accuracy for a given confidence level. The narrower the interval, the lower the Score. The more it misses the interval, the more it is penalized and the score increases. Therefore, the lower the Score the better. For example, for forecasts with a confidence level of 95%, the model that would show a better score would be the STL Decomposition Model, being the one that has the best balance between having a narrower range and not falling outside the range.\n\n\n# A tibble: 6 × 3\n  .model                .type winkler\n  &lt;chr&gt;                 &lt;chr&gt;   &lt;dbl&gt;\n1 STL decomposition     Test    2514.\n2 Exp. Smo. ETS(M,Ad,M) Test    2710.\n3 ARIMA(1,1,9)(1,1,0)   Test    2793.\n4 ARIMA(3,1,2)(0,0,2)   Test    2861.\n5 Neu. Net AR (10,1,3)  Test    3517.\n6 Prophet               Test    4477.\n\n\nSimilarly, the Quantile Score may be useful if someone is more interested in not exceeding the lower or upper limit of the inteval. A specific score can be used for a given quantile. For instance, if someone’s priority is to satisfy a demand and not producing less than can be sold, a quantile of 1% can be used:\n\n\n# A tibble: 6 × 3\n  .model                .type    qs\n  &lt;chr&gt;                 &lt;chr&gt; &lt;dbl&gt;\n1 STL decomposition     Test   20.4\n2 ARIMA(1,1,9)(1,1,0)   Test   22.1\n3 ARIMA(3,1,2)(0,0,2)   Test   25.5\n4 Exp. Smo. ETS(M,Ad,M) Test   31.0\n5 Neu. Net AR (10,1,3)  Test   46.2\n6 Prophet               Test   90.9\n\n\nOn the other hand, if someone’s priority was not to waste product and not to produce more than could be sold in order to avoid shrinkage, a 90% quantile can be used:\n\n\n# A tibble: 6 × 3\n  .model                .type    qs\n  &lt;chr&gt;                 &lt;chr&gt; &lt;dbl&gt;\n1 ARIMA(3,1,2)(0,0,2)   Test   207.\n2 Prophet               Test   224.\n3 Neu. Net AR (10,1,3)  Test   235.\n4 Exp. Smo. ETS(M,Ad,M) Test   236.\n5 STL decomposition     Test   241.\n6 ARIMA(1,1,9)(1,1,0)   Test   265.\n\n\n\n\nFinally, a comparison of the different forecasts for the next 10 periods is presented, showing their confidence intervals.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccording to the particular needs different Models can be recommended. In general terms the Exponential Smoothing Model ETS(M,Ad,M) is the one that shows both a better point accuracy and a better confidence interval as measured by the Skill Score.\nHowever, if a confidence level has been determined beforehand, for example 95%, the model with the best confidence interval would be the STL Decomposition Model measured by the Winkler Score.\nLikewise, if what matters most is to satisfy a demand and not generate less than what might be needed, for example for a 99% confidence, the STL Decomposition Model would also be the best according to the Quantile Score for a 1% quantile.\nOn the other hand, if the main concern is not to generate more than what might be needed (as to avoid shrinkage), for example, for a 90% confidence level, the indicated model would be the ARIMA(3,1,2)(0,0,2) model according to the Quantile Score for a 90% quantile."
  },
  {
    "objectID": "english.html#packages",
    "href": "english.html#packages",
    "title": "English Version",
    "section": "",
    "text": "Packages loaded in the library required for this analysis.\n\n# Packages\npackages = c('dplyr','ggplot2','tsibble','fable','feasts',\n             'gridExtra','tseries','fable.prophet','plotly')\nlapply(packages, library, character.only=TRUE)"
  },
  {
    "objectID": "english.html#data-preparation",
    "href": "english.html#data-preparation",
    "title": "English Version",
    "section": "",
    "text": "First, the loaded database is prepared in order to select only the data of the series of interest, group the information by months and convert the units of the sales volume in pounds to tons. We are interested in knowing the total US monthly volume of organic avocados.\n\nserie = avocado_data %&gt;% \n  select(Date, TotalVolume, type, region) %&gt;% \n  filter(type == \"organic\" & region == \"TotalUS\") %&gt;%\n  mutate(Month = yearmonth(Date)) %&gt;% \n  group_by(Month) %&gt;% summarise(Volume = sum(TotalVolume)) %&gt;% \n  filter(row_number() &lt;= n()-1) %&gt;% #Remove last row due to incomplete information\n  as_tsibble(index = Month)\n\n# Convert volume from pounds to tons\nserie$Volume = (serie$Volume * 0.453592)/1000"
  },
  {
    "objectID": "english.html#analyze-original-series-seasonality-and-heteroscedasticity.",
    "href": "english.html#analyze-original-series-seasonality-and-heteroscedasticity.",
    "title": "English Version",
    "section": "",
    "text": "First, the original series is analyzed and the presence of seasonality is investigated.\n\n# Plot Original Series\ngraf_san = serie %&gt;% autoplot(Volume) + geom_point() + \n  labs(y = \"Thousands of tons\", x = \"\",\n       title = \"Avocado sales volume in the U.S., 2015-2023\")\nggplotly(graf_san)\n\n\n\n\n\nIt can be seen that the series has a positive trend, as well as the possible presence of heteroscedasticity and seasonality.\n\n\n\nThe following seasonality plots with the gg_season() and gg_subseries() functions confirm the presence of seasonality.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen suspecting the presence of heteroscedasticity, a first difference is drawn to see how it behaves over time.\n\n# First Difference\nserie_dif = \n  serie %&gt;%\n  mutate(Difference = difference(Volume, order_by = Month)) %&gt;%\n  select(-Volume) %&gt;%\n  filter(row_number() &gt; 1)\n\n# Graficar First Difference\ngraf_serie_dif = serie_dif %&gt;% autoplot(Difference) +\n  geom_hline(yintercept = mean(serie_dif$Difference),lty=2,col=\"red\") +\n  geom_point() + \n  labs(title = \"First Difference\", x=\"\")\n\nggplotly(graf_serie_dif)\n\n\n\n\n\nLooking at the plot of the first difference confirms the presence of heteroscedasticity as the variance increases over time. Therefore, it will be necessary to perform some transformation."
  },
  {
    "objectID": "english.html#series-transformation",
    "href": "english.html#series-transformation",
    "title": "English Version",
    "section": "",
    "text": "A Box-Cox transformation will be performed to deal with the heteroscedasticity of the series for which the Guerrero method will be used to obtain it.\n\n# Estimating Lambda\nlambda = \n  serie %&gt;%\n  features(Volume, features = guerrero) %&gt;%\n  pull(lambda_guerrero)\n\n# Transformed Series\ngraf_st = serie %&gt;% \n  autoplot(box_cox(Volume,lambda)) + \n  geom_point() + \n  labs(\n    title = \"Box-Cox transformed series\",\n    x =\"\", y= \"\"\n  )\n\n# Original and transformed series comparison graphs\ngrid.arrange(graf_san,graf_st)\n\n\n\n\n\n\n\n\nA comparison of the first difference of the original series and the transformed series is also used to show how heteroscedasticity is corrected by the transformation."
  },
  {
    "objectID": "english.html#series-decomposition",
    "href": "english.html#series-decomposition",
    "title": "English Version",
    "section": "",
    "text": "The following is a decomposition of the series into its various components using the STL method, which stands for Seasonal and Trend decomposition using Loess.\n\n\n\n\n\n\n\n\n\nTo better identify trend changes in the trend-cycle indicator, a graph is made where it changes color according to its direction.\n\n# Trend-Cycle\ntrend_cycle = \n  serie %&gt;%\n  model(STL(box_cox(Volume,lambda))) %&gt;%\n  components() %&gt;%\n  select(Month, trend) %&gt;%\n  mutate(dif = difference(trend))\n\n# Shifting Color for Plotting\nccpg = c()\n#Note: One period is lagged to coincide with the start of the changeover.\nfor (i in 2:nrow(trend_cycle)){\n  if(trend_cycle$dif[i] &gt;= 0){\n    ccpg = append(ccpg, 'black')\n  }else{\n    ccpg = append(ccpg, 'red')\n  }\n}\n#last color equal to the last color available\nccpg = append(ccpg, ccpg[length(ccpg)])\n\n# Trend-Cycle Graph\ntrend_cycle %&gt;%\n  select(-dif) %&gt;%\n  mutate(trend = inv_box_cox(trend,lambda)) %&gt;%\n  ggplot(aes(x = Month, y = trend)) + \n  geom_line(col=ccpg, lwd=1.5) +\n  labs(title = \"Avocado Sales Volume Trend-Cycle\",\n       subtitle = \"United States, 2015 - 2023\",\n       y = \"Thousands of tons\", x = \"\",\n       )"
  },
  {
    "objectID": "english.html#training-and-test-data-sets",
    "href": "english.html#training-and-test-data-sets",
    "title": "English Version",
    "section": "",
    "text": "To evaluate the accuracy of the forecasts, the series is separated into a training data set and a test data set. For this exercise we seek to forecast the following 10 periods (Months).\n\n# Steps to forecast\npap = 10\n\n# Training Data\ntrain_ini = substr(as.character(as.Date(serie$Month[1])),1,7)\ntrain_end = substr(as.character(as.Date(serie$Month[nrow(serie)-pap])),1,7)\ntrain_data = serie %&gt;%\n  filter_index(train_ini ~ train_end)\n\n# Test Data\ntest_ini = substr(as.character(as.Date(serie$Month[nrow(serie) - pap + 1])),1,7)\ntest_data = serie %&gt;% filter_index(test_ini ~.)"
  },
  {
    "objectID": "english.html#exponential-smoothing",
    "href": "english.html#exponential-smoothing",
    "title": "English Version",
    "section": "",
    "text": "The first model to review is the Exponential Smoothing model for which we are going to use the characteristics of the behavior of the series previously identified to give us an idea of what would be the best model for the series we have.\nIdentified characteristics:\n\nTrend\nSeasonality\nHeterocedasticity\n\nSince these characteristics are detected, the following models will be analyzed:\n\nETS(M,A,M)\nETS(M,Ad,M)\n\nIn addition, it is reviewed whether the Automatic Model represents a good alternative.\n\n# Models to Review\nmod_se = train_data %&gt;%\n  model(\n    Auto = ETS(Volume), # Automatic model &lt;ETS(M,Ad,A)&gt;\n    MAM = ETS(Volume ~ error(\"M\") + trend(\"A\") + season(\"M\")),\n    MAdM = ETS(Volume ~ error(\"M\") + trend(\"Ad\") + season(\"M\")),\n  )\n\n\n# Information Criteria (AICc)\nglance(mod_se) %&gt;% arrange(AICc)\n\n# A tibble: 3 × 9\n  .model sigma2 log_lik   AIC  AICc   BIC     MSE    AMSE   MAE\n  &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Auto   0.0243   -792. 1620. 1628. 1666. 156246. 158324. 0.117\n2 MAM    0.0249   -795. 1625. 1633. 1669. 168550. 176817. 0.121\n3 MAdM   0.0260   -795. 1626. 1635. 1672. 155850. 159705. 0.121\n\n\nAlthough the ETS(M,Ad,A) automatic model seems to show a better information criterion of AICc, it uses an additive stationarity, which given the heteroscedasticity of the model is not recommended, so we will select the ETS(M,Ad,M) model, which makes more sense given the behavior of the series.\nWhen evaluating the accuracy of the models, it is observed that the ETS(M,Ad,M) model has a better performance than the ETS(M,A,M) model, so we will use the latter, which is an Exponential Smoothing with Damped Trend, Multiplicative Stationarity and Multiplicative Errors.\n\n\n# A tibble: 3 × 4\n  .model  RMSE   MAE  MAPE\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Auto    437.  397.  11.8\n2 MAdM    467.  417.  12.3\n3 MAM     592.  452.  13.7\n\n\n\n\n\nOnce the model to be used has been identified, it must be validated by analyzing its residuals. First we will review the assumptions of \\(E[mu]=0\\) and homoscedasticity.\n\n\n\n\n\n\n\n\n\nIt can be seen that these assumptions are fulfilled, now it remains to see the assumption of normality.\n\n\n\nWe seek to analyze by means of histogram, quantile-quantile plots and the Jarque-Bera test the assumption of normality of the residuals of the model.\n\n# Residuals histogram\nhist_plot = residuals %&gt;% ggplot(aes(x = .innov)) +\n  geom_histogram(bins = 20, lwd = 1.5,col = 'white', fill = 'slategrey') +\n  labs(title = \"Residuals Normality Check: Histogram and Quantile-Quantile\", \n       x = \"Residuals\", y =\"Frequency\")\n# Q-Q Plot\nqq_plot = residuals %&gt;% ggplot(aes(sample = .innov)) + \n  stat_qq(col = 'slateblue') + stat_qq_line() +\n  labs(x = \"Theoretical Quantiles\", y =\"Sample Quantiles\")\ngrid.arrange(hist_plot,qq_plot)\n\n\n\n\n\n\n\n# Jarque-Bera Test\n# p-value &gt; 0.05 indicates that it cannot be rejected as normally distributed.\njarque.bera.test(residuals$.innov)\n\n\n    Jarque Bera Test\n\ndata:  residuals$.innov\nX-squared = 1.4323, df = 2, p-value = 0.4886\n\n\nIt may be debatable whether the assumption of normality can be considered valid given the plots and the test that indicates that it cannot be rejected that the residuals are normally distributed.\nIn this situation, two alternatives are offered for the generation of confidence intervals. They can be performed assuming normal distribution, or also by means of a Bootstrap simulation.\n\n\n\n\n# Plot Forecast vs. Actual Values (Normal Distribution Assumption)\ngraf_se_dn = mod_se %&gt;% select(MAdM) %&gt;% forecast(h = pap) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Month &gt;= yearmonth(\"2019-01-01\")),\n    lwd = 1.5,\n    level = 80\n  ) +\n  labs(title = \"Exponential Smoothing Forecast ETS(M,Ad,M)\",\n       subtitle = \"ETS(M,Ad,M) Model with Normally Distributed Intervals\",\n       x = \"\")\n\n# Plot Forecast vs. Actual Values (Bootstrap)\ngraf_se_boot = mod_se %&gt;% select(MAdM) %&gt;% forecast(h = pap, bootstrap = TRUE) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Month &gt;= yearmonth(\"2019-01-01\")),\n      lwd = 1.5,\n    level = 80\n  ) +\n  labs(subtitle = \"ETS(M,Ad,M) Model with Bootstrap Intervals\",\n       x = \"\")\ngrid.arrange(graf_se_dn,graf_se_boot)\n\n\n\n\n\n\n\n\nNote that no major differences are observed between the two types of intervals."
  },
  {
    "objectID": "english.html#arima",
    "href": "english.html#arima",
    "title": "English Version",
    "section": "",
    "text": "The second model to review is the Seasonal ARIMA or SARIMA for which we will also take advantage of the previously identified characteristics of the behavior of the series to give us an idea of which would be the best models. As the series has trend and seasonality, one or more differences may need to be drawn. On the other hand, the Box-Cox transformation can be used to correct for heteroscedasticity.\n\n\nFirst we need the series to be stationary, for which we calculated seasonal differences and first difference to identify if it is convenient to estimate more than one difference and if the first difference or the seasonal difference is preferred. When applying seasonal difference, it was not enough and another difference had to be computed On the other hand, by estimating only the first difference, it seems to be enough to make the series stationary.\n\n# diff(box_cox(Volume,lambda)) Mean for stationarity graph\nm_dif= train_data %&gt;% \n  mutate(dif_vol = difference(box_cox(Volume,lambda))) %&gt;%\n  pull(dif_vol) %&gt;% mean(na.rm = TRUE)\n\n# Plot of Differences Required for Stationarity\ntrain_data %&gt;% autoplot(\n  box_cox(Volume,lambda) %&gt;%\n    difference(1)\n)  + geom_point() +\n  labs(\n  title = \"Stationarity Graph\",\n  x = \"\", y = \"\"\n) +\n  geom_hline(yintercept = m_dif, lty=2, col=\"red\")\n\n\n\n\n\n\n\n\nThe Unit Root and Seasonal Strength tests can also be used to detect which differences would be more convenient to calculate.\n\n# Seasonal Difference Test\n# seasonal_strength_year &gt;= 0.64 indicates to calculate seasonal difference\ntrain_data %&gt;% features(box_cox(Volume,lambda), feat_stl)\n\n# A tibble: 1 × 9\n  trend_strength seasonal_strength_year seasonal_peak_year seasonal_trough_year\n           &lt;dbl&gt;                  &lt;dbl&gt;              &lt;dbl&gt;                &lt;dbl&gt;\n1          0.877                  0.506                  5                   11\n# ℹ 5 more variables: spikiness &lt;dbl&gt;, linearity &lt;dbl&gt;, curvature &lt;dbl&gt;,\n#   stl_e_acf1 &lt;dbl&gt;, stl_e_acf10 &lt;dbl&gt;\n\n# Number of Seasonal Differences Required\ntrain_data %&gt;% features(box_cox(Volume,lambda), unitroot_nsdiffs)\n\n# A tibble: 1 × 1\n  nsdiffs\n    &lt;int&gt;\n1       0\n\n# Unit Root Test\n# kpss_pvalue &lt; 0.05 indicates calculate difference\ntrain_data %&gt;% features(box_cox(Volume,lambda), unitroot_kpss)\n\n# A tibble: 1 × 2\n  kpss_stat kpss_pvalue\n      &lt;dbl&gt;       &lt;dbl&gt;\n1      2.08        0.01\n\n# Number of Differences Required\ntrain_data %&gt;% features(box_cox(Volume,lambda), unitroot_ndiffs)\n\n# A tibble: 1 × 1\n  ndiffs\n   &lt;int&gt;\n1      1\n\n\nThe various tests indicate that the recommended approach would be not to calculate seasonal difference and to calculate first difference.\n\n\n\nThe next step would be to review the Sample and Partial Autocorrelation plots to identify tentative models.\n\n# Sample and Partial Autocorrelation Function Plots: ACF y PACF\nacf_plot = autoplot(ACF(train_data, difference(box_cox(Volume,lambda)), lag_max = 36)) +\n  labs(y = \"ACF\", x=\"\", title = \"Sample and Partial Autocorrelation Functions: ACF and PACF\")\npacf_plot = autoplot(PACF(train_data, difference(box_cox(Volume,lambda)), lag_max = 36)) +\n  labs(y = \"PACF\", x= \"Lags\")\ngrid.arrange(acf_plot,pacf_plot)\n\n\n\n\n\n\n\n\n\n\n\nDifferent models were estimated based on the lags shown in the ACF and PACF and the analysis of residuals.\n\n# Estimate Model (d=1,D=0)\nmod_arima = train_data %&gt;% \n  model(\n    m210_002 = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(2,1,0) + PDQ(0,0,2)),\n    m011_002 = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(0,1,1) + PDQ(0,0,2)),\n    m810_002_c = ARIMA(box_cox(Volume,lambda) ~ 1 + pdq(8,1,0) + PDQ(0,0,2)),\n    m217_002_c = ARIMA(box_cox(Volume,lambda) ~ 1 + pdq(2,1,7) + PDQ(0,0,2)),\n    m312_002 = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(3,1,2) + PDQ(0,0,2)),\n    m119_002 = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(1,1,9) + PDQ(0,0,2))\n  )\n# Models sorted by AICc\nglance(mod_arima) %&gt;% arrange(AICc)\n\n# A tibble: 6 × 8\n  .model     sigma2 log_lik   AIC  AICc   BIC ar_roots  ma_roots  \n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;    &lt;list&gt;    \n1 m810_002_c   20.2   -278.  580.  583.  610. &lt;cpl [8]&gt; &lt;cpl [24]&gt;\n2 m217_002_c   19.4   -277.  580.  584.  613. &lt;cpl [2]&gt; &lt;cpl [31]&gt;\n3 m210_002     21.7   -287.  584.  585.  597. &lt;cpl [2]&gt; &lt;cpl [24]&gt;\n4 m119_002     19.6   -277.  581.  585.  614. &lt;cpl [1]&gt; &lt;cpl [33]&gt;\n5 m011_002     22.8   -290.  587.  588.  597. &lt;cpl [0]&gt; &lt;cpl [25]&gt;\n6 m312_002     22.2   -286.  588.  590.  609. &lt;cpl [3]&gt; &lt;cpl [26]&gt;\n\n# Forecast Accuracy\nmod_arima %&gt;% forecast(h = pap) %&gt;% accuracy(test_data) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 6 × 4\n  .model      RMSE   MAE  MAPE\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 m312_002    413.  328.  9.20\n2 m119_002    423.  338.  9.56\n3 m810_002_c  417.  336. 10.2 \n4 m210_002    486.  386. 10.7 \n5 m011_002    516.  412. 11.5 \n6 m217_002_c  674.  587. 17.9 \n\n\nTheir analysis was separated by differentiation for comparability.\n\n# Estimate Model (d=1,D=1)\nmod_arima = train_data %&gt;% \n  model(\n    m119_110 = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(1,1,9) + PDQ(1,1,0)),\n    m119_011 = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(1,1,9) + PDQ(0,1,1))\n  )\n# Models sorted by AICc\nglance(mod_arima) %&gt;% arrange(AICc)\n\n# A tibble: 2 × 8\n  .model   sigma2 log_lik   AIC  AICc   BIC ar_roots   ma_roots  \n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;     &lt;list&gt;    \n1 m119_011   22.9   -251.  525.  530.  554. &lt;cpl [1]&gt;  &lt;cpl [21]&gt;\n2 m119_110   23.5   -252.  527.  532.  556. &lt;cpl [13]&gt; &lt;cpl [9]&gt; \n\n# Forecast Accuracy\nmod_arima %&gt;% forecast(h = pap) %&gt;% accuracy(test_data) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 2 × 4\n  .model    RMSE   MAE  MAPE\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 m119_110  425.  324.  9.18\n2 m119_011  502.  411. 12.2 \n\n\nY después se eligieron los mejores modelos.\n\n\n# A tibble: 4 × 8\n  .model     sigma2 log_lik   AIC  AICc   BIC ar_roots   ma_roots  \n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt;     &lt;list&gt;    \n1 m119_110     23.5   -252.  527.  532.  556. &lt;cpl [13]&gt; &lt;cpl [9]&gt; \n2 m810_002_c   20.2   -278.  580.  583.  610. &lt;cpl [8]&gt;  &lt;cpl [24]&gt;\n3 m119_002     19.6   -277.  581.  585.  614. &lt;cpl [1]&gt;  &lt;cpl [33]&gt;\n4 m312_002     22.2   -286.  588.  590.  609. &lt;cpl [3]&gt;  &lt;cpl [26]&gt;\n\n\n# A tibble: 4 × 4\n  .model      RMSE   MAE  MAPE\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 m119_110    425.  324.  9.18\n2 m312_002    413.  328.  9.20\n3 m119_002    423.  338.  9.56\n4 m810_002_c  417.  336. 10.2 \n\n\nThe same process was followed for the validation of each model.\n\n\n\nThe statistical significance of its components was reviewed and their residuals were extracted to analyze whether the assumptions were met.\n\n# Model to Review\nmar = \"m312_002\"\nresiduals = augment(mod_arima) %&gt;% filter(.model == mar) # Residuals of the Model to Review\n\n# Review significance of values\n#tidy(mod_arima)\nmod_arima %&gt;% select(mar) %&gt;% tidy() %&gt;% print(n=20)\n\n# A tibble: 7 × 6\n  .model   term  estimate std.error statistic   p.value\n  &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 m312_002 ar1    -0.0251     0.256   -0.0980 0.922    \n2 m312_002 ar2     0.276      0.149    1.85   0.0671   \n3 m312_002 ar3     0.357      0.133    2.68   0.00873  \n4 m312_002 ma1    -0.731      0.251   -2.91   0.00450  \n5 m312_002 ma2    -0.169      0.190   -0.888  0.377    \n6 m312_002 sma1    0.511      0.110    4.65   0.0000108\n7 m312_002 sma2    0.518      0.153    3.39   0.00102  \n\n\nThe residuals were plotted so that the assumptions of \\(E[mu]=0\\) and homoscedasticity were met.\n\n\n\n\n\n\n\n\n\nACF and PACF plots of the residuals were plotted to check for remaining autocorrelation in the model.\n\n\n\n\n\n\n\n\n\nAs well as the Ljung-Box test.\n\n\n# A mable: 1 x 1\n                   m312_002\n                    &lt;model&gt;\n1 &lt;ARIMA(3,1,2)(0,0,2)[12]&gt;\n\n\n# A tibble: 1 × 3\n  .model   lb_stat lb_pvalue\n  &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 m312_002    43.1  0.000469\n\n\n\n\n\nWe seek to analyze by means of histogram, Q-Q plots and the Jarque-Bera test the assumption of normality of the residuals of the model.\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  residuals$.innov\nX-squared = 1.6021, df = 2, p-value = 0.4489\n\n\n\n\n\nThe forecasts of the main models were plotted for comparison.\n\n# Forecasting the Top 4 ARIMA Models\n# ARIMA Models for Plotting\nmod_arima_pg = mod_arima %&gt;% \n  select(\n    `ARIMA(1,1,9)(0,0,2)[12]` = m119_002,\n    `ARIMA(3,1,2)(0,0,2)[12]` = m312_002,\n    `ARIMA(8,1,0)(0,0,2)[12] c/ tendencia` = m810_002_c,\n    `ARIMA(1,1,9)(1,1,0)[12]` = m119_110\n  )\n\n# Plot Forecast vs. Actual values\ngraf_arima_4m = mod_arima_pg %&gt;% \n  forecast(h = pap) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Month &gt;= yearmonth(\"2021-01-01\")),\n    level = NULL\n  ) +\n  labs(title = \"Forecasting with ARIMA Models\",x = \"\") +\n  theme(legend.position='none')  +\n  facet_wrap(vars(.model), ncol = 2)\n\nggplotly(graf_arima_4m)\n\n\n\n\n\nNote: You can hover the cursor over the graph to see the values of each point.\nTheir confidence intervals were also plotted.\n\n# Plotting individual models with confidence intervals\nmod_arima_pg %&gt;% forecast(h = pap) %&gt;%\n  autoplot(\n    serie %&gt;% filter(Month &gt;= yearmonth(\"2019-01-01\")),\n    lwd = 1.5,\n  ) +\n  labs(title = \"Forecasting with ARIMA Models\", x = \"\",\n       subtitle = \"80% and 95% confidence intervals\") +\n  theme(legend.position='none')  +\n  facet_wrap(vars(.model), scales = \"free\", ncol = 2)"
  },
  {
    "objectID": "english.html#forecasting-with-stl-decomposition",
    "href": "english.html#forecasting-with-stl-decomposition",
    "title": "English Version",
    "section": "",
    "text": "Afterwards, the STL Decomposition model was reviewed, which uses the previously used method to decompose the series, to subsequently deseasonalize the series and apply a seasonal component by means of some other method, such as exponential smoothing (ETS). Since only one method is used, in this case we go directly to the residual analysis.\n\n# Estimate Model (ETS)\nmod_stl = train_data %&gt;% \n  model(\n    dstl = decomposition_model(\n      STL(box_cox(Volume,lambda)), #Decomposition method\n      ETS(season_adjust), #Seasonally adjusted series\n      ETS(season_year) #Seasonal component\n      )\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  residuals$.innov\nX-squared = 0.81585, df = 2, p-value = 0.665\n\n\n\n\n\nForecasts are made with confidence intervals with the assumption of normality and Bootstrap."
  },
  {
    "objectID": "english.html#forecasting-with-prophet",
    "href": "english.html#forecasting-with-prophet",
    "title": "English Version",
    "section": "",
    "text": "Forecasts were also made with the Facebook Prophet model using different orders and looking at their accuracy to choose the best model.\n\n# Estimating Models\nset.seed(10)\nmod_prophet = train_data %&gt;% \n  model(\n    `Order = 10` = prophet(Volume ~ season(\n      period=\"year\", order = 10, type = \"multiplicative\")),\n    `Order = 5` = prophet(Volume ~ season(\n      period=\"year\", order = 5, type = \"multiplicative\")),\n    `Order = 3` = prophet(Volume ~ season(\n      period=\"year\", order = 3, type = \"multiplicative\")),\n    `Order = 2` = prophet(Volume ~ season(\n      period=\"year\", order = 2, type = \"multiplicative\"))\n    )\n\n# Forecast Accuracy\nmod_prophet %&gt;% forecast(h = pap) %&gt;% accuracy(test_data) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 4 × 4\n  .model      RMSE   MAE  MAPE\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Order = 10  748.  579.  17.8\n2 Order = 5   738.  619.  18.9\n3 Order = 2   761.  651.  20.0\n4 Order = 3   788.  652.  20.1\n\n\nOnce the best model has been identified, it is validated.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  residuals$.innov\nX-squared = 1.5829, df = 2, p-value = 0.4532\n\n\n\n\n\nThe forecasts of the main models were plotted for comparison.\n\n\n\n\n\n\nNote: You can hover the cursor over the graph to see the values of each point.\nForecasts are also performed to check the confidence intervals of each model."
  },
  {
    "objectID": "english.html#forecasting-with-neural-network-autoregression-nnar",
    "href": "english.html#forecasting-with-neural-network-autoregression-nnar",
    "title": "English Version",
    "section": "",
    "text": "The Neural Network AutoRegressive Regression (NNAR) model is also reviewed to expand the options offered. For this model, different numbers of nodes are reviewed and their accuracy is reviewed to choose the best model.\n\n# Estimating Models NNAR\nset.seed(10) # set random numbers\nmod_rn = train_data %&gt;% \n  model(\n    `NNAR(10,1,2)` = NNETAR(box_cox(Volume,lambda),n_nodes=2),\n    `NNAR(10,1,3)` = NNETAR(box_cox(Volume,lambda),n_nodes=3),\n    `NNAR(10,1,4)` = NNETAR(box_cox(Volume,lambda),n_nodes=4),\n    `NNAR(10,1,6)` = NNETAR(box_cox(Volume,lambda),n_nodes=6)\n  )\n\n# Forecast Accuracy\nmod_rn %&gt;% forecast(h = pap) %&gt;% accuracy(test_data) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 4 × 4\n  .model        RMSE   MAE  MAPE\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 NNAR(10,1,3)  363.  345.  10.1\n2 NNAR(10,1,2)  379.  353.  10.5\n3 NNAR(10,1,4)  404.  379.  11.0\n4 NNAR(10,1,6)  467.  416.  11.9\n\n\nOnce the best model has been identified, it is validated.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    Jarque Bera Test\n\ndata:  na.omit(residuals$.innov)\nX-squared = 3.5995, df = 2, p-value = 0.1653\n\n\n\n\n\nForecasts are made with confidence intervals with the assumption of normality and Bootstrap.\n\n\n\n\n\n\n\n\n\nThe forecasts of the main models were plotted for comparison.\n\n\n\n\n\n\nNote: You can hover the cursor over the graph to see the values of each point.\nForecasts are also performed to check the confidence intervals of each model."
  },
  {
    "objectID": "english.html#cross-validation",
    "href": "english.html#cross-validation",
    "title": "English Version",
    "section": "",
    "text": "In order to perform a more complete evaluation of the point accuracy of the best models so far analyzed, a cross-validation is performed, which is a more sophisticated version of the training and test sets.\nFor this procedure it is necessary to first make an extended series to go through a window where the size of the training set will be increased to see the accuracy in different scenarios and obtain an average error of these to evaluate the accuracy of each model.\n\n# Create extended series with index for Cross-Validation\nserie_alargada = serie %&gt;% \n  stretch_tsibble(.init = 80, .step = 10) %&gt;%\n  filter(.id != max(.id))\n\n# Models for cross-validation\nset.seed(10)\nmod_vc = serie_alargada %&gt;%\n  model(\n    `Exp. Smo. ETS(M,Ad,M)` = ETS(Volume ~ error(\"M\") + trend(\"Ad\") + season(\"M\")),\n    `ARIMA(1,1,9)(1,1,0)` = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(1,1,9) + PDQ(1,1,0)),\n    `ARIMA(3,1,2)(0,0,2)` = ARIMA(box_cox(Volume,lambda) ~ 0 + pdq(3,1,2) + PDQ(0,0,2)),\n    `STL decomposition` = decomposition_model(STL(box_cox(Volume,lambda)),\n                                              ETS(season_adjust), ETS(season_year)),\n    `Prophet` = prophet(Volume ~ season(\n      period=\"year\", order = 10, type = \"multiplicative\")),\n    `Neu. Net AR (10,1,3)` = NNETAR(box_cox(Volume,lambda),n_nodes=3)\n  )\n\nmod_vc %&gt;% forecast(h = 10) %&gt;% accuracy(serie) %&gt;% \n  select(.model,RMSE,MAE,MAPE) %&gt;% arrange(MAPE)\n\n# A tibble: 6 × 4\n  .model                 RMSE   MAE  MAPE\n  &lt;chr&gt;                 &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Exp. Smo. ETS(M,Ad,M)  500.  398.  10.6\n2 ARIMA(3,1,2)(0,0,2)    541.  423.  12.4\n3 Prophet                617.  500.  14.3\n4 Neu. Net AR (10,1,3)   618.  527.  14.8\n5 STL decomposition      613.  513.  15.0\n6 ARIMA(1,1,9)(1,1,0)    648.  601.  17.3"
  },
  {
    "objectID": "english.html#distribution-accuracy",
    "href": "english.html#distribution-accuracy",
    "title": "English Version",
    "section": "",
    "text": "It is also important to analyze the accuracy of the confidence intervals of the implemented models, for which different ways of evaluating the models are shown. These models will be evaluated for 10-period forecasts.\nWe start with the Skill Score, which helps to rank the overall accuracy of the confidence intervals from best to worst, where the higher this score is, the more accurate the possible confidence intervals returned by the model will be.\n\n\n# A tibble: 6 × 3\n  .model                .type skill\n  &lt;chr&gt;                 &lt;chr&gt; &lt;dbl&gt;\n1 Exp. Smo. ETS(M,Ad,M) Test  0.367\n2 ARIMA(3,1,2)(0,0,2)   Test  0.284\n3 STL decomposition     Test  0.228\n4 Neu. Net AR (10,1,3)  Test  0.173\n5 ARIMA(1,1,9)(1,1,0)   Test  0.166\n6 Prophet               Test  0.160\n\n\nThe above table shows that the Exponential Smoothing model ETS(M,Ad,M) has the best overall accuracy, regardless of the confidence level. However, the evaluation can be customized according to different needs, such as specific confidence intervals, or prioritizing the lower or upper part of the interval.\nOn the other hand, the Winkler Score measures the accuracy for a given confidence level. The narrower the interval, the lower the Score. The more it misses the interval, the more it is penalized and the score increases. Therefore, the lower the Score the better. For example, for forecasts with a confidence level of 95%, the model that would show a better score would be the STL Decomposition Model, being the one that has the best balance between having a narrower range and not falling outside the range.\n\n\n# A tibble: 6 × 3\n  .model                .type winkler\n  &lt;chr&gt;                 &lt;chr&gt;   &lt;dbl&gt;\n1 STL decomposition     Test    2514.\n2 Exp. Smo. ETS(M,Ad,M) Test    2710.\n3 ARIMA(1,1,9)(1,1,0)   Test    2793.\n4 ARIMA(3,1,2)(0,0,2)   Test    2861.\n5 Neu. Net AR (10,1,3)  Test    3517.\n6 Prophet               Test    4477.\n\n\nSimilarly, the Quantile Score may be useful if someone is more interested in not exceeding the lower or upper limit of the inteval. A specific score can be used for a given quantile. For instance, if someone’s priority is to satisfy a demand and not producing less than can be sold, a quantile of 1% can be used:\n\n\n# A tibble: 6 × 3\n  .model                .type    qs\n  &lt;chr&gt;                 &lt;chr&gt; &lt;dbl&gt;\n1 STL decomposition     Test   20.4\n2 ARIMA(1,1,9)(1,1,0)   Test   22.1\n3 ARIMA(3,1,2)(0,0,2)   Test   25.5\n4 Exp. Smo. ETS(M,Ad,M) Test   31.0\n5 Neu. Net AR (10,1,3)  Test   46.2\n6 Prophet               Test   90.9\n\n\nOn the other hand, if someone’s priority was not to waste product and not to produce more than could be sold in order to avoid shrinkage, a 90% quantile can be used:\n\n\n# A tibble: 6 × 3\n  .model                .type    qs\n  &lt;chr&gt;                 &lt;chr&gt; &lt;dbl&gt;\n1 ARIMA(3,1,2)(0,0,2)   Test   207.\n2 Prophet               Test   224.\n3 Neu. Net AR (10,1,3)  Test   235.\n4 Exp. Smo. ETS(M,Ad,M) Test   236.\n5 STL decomposition     Test   241.\n6 ARIMA(1,1,9)(1,1,0)   Test   265.\n\n\n\n\nFinally, a comparison of the different forecasts for the next 10 periods is presented, showing their confidence intervals."
  },
  {
    "objectID": "english.html#conclusions",
    "href": "english.html#conclusions",
    "title": "English Version",
    "section": "",
    "text": "According to the particular needs different Models can be recommended. In general terms the Exponential Smoothing Model ETS(M,Ad,M) is the one that shows both a better point accuracy and a better confidence interval as measured by the Skill Score.\nHowever, if a confidence level has been determined beforehand, for example 95%, the model with the best confidence interval would be the STL Decomposition Model measured by the Winkler Score.\nLikewise, if what matters most is to satisfy a demand and not generate less than what might be needed, for example for a 99% confidence, the STL Decomposition Model would also be the best according to the Quantile Score for a 1% quantile.\nOn the other hand, if the main concern is not to generate more than what might be needed (as to avoid shrinkage), for example, for a 90% confidence level, the indicated model would be the ARIMA(3,1,2)(0,0,2) model according to the Quantile Score for a 90% quantile."
  }
]